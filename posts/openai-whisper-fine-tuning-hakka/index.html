<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Openai Whisper Fine-Tuning - Hakka | Aura's Space</title><meta name=keywords content><meta name=description content="é€£çµ
Github
é‡é»å°ˆæ¡ˆçµæ§‹
whisper_hakka
 â”—â”³â” audio
  â”ƒ   â”£â” test
  â”ƒ   â”ƒ   â”—â” testèªæ–™å­˜æ”¾å€
  â”ƒ   â”£â” train
  â”ƒ   â”ƒ   â”—â” trainèªæ–™å­˜æ”¾å€
  â”ƒ   â”—â” metadata.csv æª”æ¡ˆè·¯å¾‘èˆ‡æ–‡æœ¬å…§å®¹
  â”£â” model
  â”ƒ   â”—â” æ¨¡å‹å­˜æ”¾å€
  â”£â” fine_tune.ipynb jupyterè¨“ç·´è…³æœ¬
  â”—â” huggingface_token huggingfaceré‡‘é‘°
å®‰è£ cuda
cuda
wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run
sudo sh cuda_11.4.0_470.42.01_linux.run
å¦‚æœè¦ç¨ç«‹è£ driverï¼Œå°±æŠŠ driver å–æ¶ˆ
driver
sudo apt-get install nvidia-driver-470
Huggingface é‡‘é‘°ç”³è«‹
è«‹åˆ°huggingface å®˜ç¶²
å³ä¸Šçš„é¸é … â†’ Settings â†’ Access Tokens
é»é¸New tokenï¼ŒNameè‡ªè¨‚ï¼ŒRoleé¸write
Generate a tokenå¾Œï¼Œå°‡ç”¢ç”Ÿçš„tokenè¤‡è£½è²¼ä¸Šåˆ°å°ˆæ¡ˆçš„huggingface_token
ç¨‹å¼ç¢¼èªªæ˜
å»ºç«‹æ¨¡å‹åç¨±
è«‹è¼¸å…¥æª”æ¡ˆåç¨±


1


model_name='model name'


ç™»å…¥ hugging face
å°‡è¨“ç·´å®Œæˆçš„æ¨¡å‹ä¸Šå‚³åˆ°å­˜æ”¾åœ¨ huggingfaceï¼Œå¯ä»¥æ¸›å°‘æœ¬åœ°ç«¯ç©ºé–“å ç”¨ã€‚
Tokenè«‹è‡ªè¡Œå» huggingface ç”³è«‹"><meta name=author content="Aura"><link rel=canonical href=https://aura.codex.tw/posts/openai-whisper-fine-tuning-hakka/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://aura.codex.tw/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://aura.codex.tw/images/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://aura.codex.tw/images/favicon.ico><link rel=apple-touch-icon href=https://aura.codex.tw/images/favicon.ico><link rel=mask-icon href=https://aura.codex.tw/images/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://aura.codex.tw/posts/openai-whisper-fine-tuning-hakka/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://aura.codex.tw/posts/openai-whisper-fine-tuning-hakka/"><meta property="og:site_name" content="Aura's Space"><meta property="og:title" content="Openai Whisper Fine-Tuning - Hakka"><meta property="og:description" content="é€£çµ Github
é‡é»å°ˆæ¡ˆçµæ§‹ whisper_hakka â”—â”³â” audio â”ƒ â”£â” test â”ƒ â”ƒ â”—â” testèªæ–™å­˜æ”¾å€ â”ƒ â”£â” train â”ƒ â”ƒ â”—â” trainèªæ–™å­˜æ”¾å€ â”ƒ â”—â” metadata.csv æª”æ¡ˆè·¯å¾‘èˆ‡æ–‡æœ¬å…§å®¹ â”£â” model â”ƒ â”—â” æ¨¡å‹å­˜æ”¾å€ â”£â” fine_tune.ipynb jupyterè¨“ç·´è…³æœ¬ â”—â” huggingface_token huggingfaceré‡‘é‘° å®‰è£ cuda cuda wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run sudo sh cuda_11.4.0_470.42.01_linux.run å¦‚æœè¦ç¨ç«‹è£ driverï¼Œå°±æŠŠ driver å–æ¶ˆ
driver sudo apt-get install nvidia-driver-470 Huggingface é‡‘é‘°ç”³è«‹ è«‹åˆ°huggingface å®˜ç¶² å³ä¸Šçš„é¸é … â†’ Settings â†’ Access Tokens é»é¸New tokenï¼ŒNameè‡ªè¨‚ï¼ŒRoleé¸write Generate a tokenå¾Œï¼Œå°‡ç”¢ç”Ÿçš„tokenè¤‡è£½è²¼ä¸Šåˆ°å°ˆæ¡ˆçš„huggingface_token
ç¨‹å¼ç¢¼èªªæ˜ å»ºç«‹æ¨¡å‹åç¨± è«‹è¼¸å…¥æª”æ¡ˆåç¨±
1 model_name='model name' ç™»å…¥ hugging face å°‡è¨“ç·´å®Œæˆçš„æ¨¡å‹ä¸Šå‚³åˆ°å­˜æ”¾åœ¨ huggingfaceï¼Œå¯ä»¥æ¸›å°‘æœ¬åœ°ç«¯ç©ºé–“å ç”¨ã€‚ Tokenè«‹è‡ªè¡Œå» huggingface ç”³è«‹"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-04T09:42:49+00:00"><meta property="article:modified_time" content="2023-07-04T09:42:49+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Openai Whisper Fine-Tuning - Hakka"><meta name=twitter:description content="é€£çµ
Github
é‡é»å°ˆæ¡ˆçµæ§‹
whisper_hakka
 â”—â”³â” audio
  â”ƒ   â”£â” test
  â”ƒ   â”ƒ   â”—â” testèªæ–™å­˜æ”¾å€
  â”ƒ   â”£â” train
  â”ƒ   â”ƒ   â”—â” trainèªæ–™å­˜æ”¾å€
  â”ƒ   â”—â” metadata.csv æª”æ¡ˆè·¯å¾‘èˆ‡æ–‡æœ¬å…§å®¹
  â”£â” model
  â”ƒ   â”—â” æ¨¡å‹å­˜æ”¾å€
  â”£â” fine_tune.ipynb jupyterè¨“ç·´è…³æœ¬
  â”—â” huggingface_token huggingfaceré‡‘é‘°
å®‰è£ cuda
cuda
wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run
sudo sh cuda_11.4.0_470.42.01_linux.run
å¦‚æœè¦ç¨ç«‹è£ driverï¼Œå°±æŠŠ driver å–æ¶ˆ
driver
sudo apt-get install nvidia-driver-470
Huggingface é‡‘é‘°ç”³è«‹
è«‹åˆ°huggingface å®˜ç¶²
å³ä¸Šçš„é¸é … â†’ Settings â†’ Access Tokens
é»é¸New tokenï¼ŒNameè‡ªè¨‚ï¼ŒRoleé¸write
Generate a tokenå¾Œï¼Œå°‡ç”¢ç”Ÿçš„tokenè¤‡è£½è²¼ä¸Šåˆ°å°ˆæ¡ˆçš„huggingface_token
ç¨‹å¼ç¢¼èªªæ˜
å»ºç«‹æ¨¡å‹åç¨±
è«‹è¼¸å…¥æª”æ¡ˆåç¨±


1


model_name='model name'


ç™»å…¥ hugging face
å°‡è¨“ç·´å®Œæˆçš„æ¨¡å‹ä¸Šå‚³åˆ°å­˜æ”¾åœ¨ huggingfaceï¼Œå¯ä»¥æ¸›å°‘æœ¬åœ°ç«¯ç©ºé–“å ç”¨ã€‚
Tokenè«‹è‡ªè¡Œå» huggingface ç”³è«‹"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://aura.codex.tw/posts/"},{"@type":"ListItem","position":2,"name":"Openai Whisper Fine-Tuning - Hakka","item":"https://aura.codex.tw/posts/openai-whisper-fine-tuning-hakka/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Openai Whisper Fine-Tuning - Hakka","name":"Openai Whisper Fine-Tuning - Hakka","description":"é€£çµ Github\né‡é»å°ˆæ¡ˆçµæ§‹ whisper_hakka â”—â”³â” audio â”ƒ â”£â” test â”ƒ â”ƒ â”—â” testèªæ–™å­˜æ”¾å€ â”ƒ â”£â” train â”ƒ â”ƒ â”—â” trainèªæ–™å­˜æ”¾å€ â”ƒ â”—â” metadata.csv æª”æ¡ˆè·¯å¾‘èˆ‡æ–‡æœ¬å…§å®¹ â”£â” model â”ƒ â”—â” æ¨¡å‹å­˜æ”¾å€ â”£â” fine_tune.ipynb jupyterè¨“ç·´è…³æœ¬ â”—â” huggingface_token huggingfaceré‡‘é‘° å®‰è£ cuda cuda wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run sudo sh cuda_11.4.0_470.42.01_linux.run å¦‚æœè¦ç¨ç«‹è£ driverï¼Œå°±æŠŠ driver å–æ¶ˆ\ndriver sudo apt-get install nvidia-driver-470 Huggingface é‡‘é‘°ç”³è«‹ è«‹åˆ°huggingface å®˜ç¶² å³ä¸Šçš„é¸é … â†’ Settings â†’ Access Tokens é»é¸New tokenï¼ŒNameè‡ªè¨‚ï¼ŒRoleé¸write Generate a tokenå¾Œï¼Œå°‡ç”¢ç”Ÿçš„tokenè¤‡è£½è²¼ä¸Šåˆ°å°ˆæ¡ˆçš„huggingface_token\nç¨‹å¼ç¢¼èªªæ˜ å»ºç«‹æ¨¡å‹åç¨± è«‹è¼¸å…¥æª”æ¡ˆåç¨±\n1 model_name=\u0026#39;model name\u0026#39; ç™»å…¥ hugging face å°‡è¨“ç·´å®Œæˆçš„æ¨¡å‹ä¸Šå‚³åˆ°å­˜æ”¾åœ¨ huggingfaceï¼Œå¯ä»¥æ¸›å°‘æœ¬åœ°ç«¯ç©ºé–“å ç”¨ã€‚ Tokenè«‹è‡ªè¡Œå» huggingface ç”³è«‹\n","keywords":[],"articleBody":"é€£çµ Github\né‡é»å°ˆæ¡ˆçµæ§‹ whisper_hakka â”—â”³â” audio â”ƒ â”£â” test â”ƒ â”ƒ â”—â” testèªæ–™å­˜æ”¾å€ â”ƒ â”£â” train â”ƒ â”ƒ â”—â” trainèªæ–™å­˜æ”¾å€ â”ƒ â”—â” metadata.csv æª”æ¡ˆè·¯å¾‘èˆ‡æ–‡æœ¬å…§å®¹ â”£â” model â”ƒ â”—â” æ¨¡å‹å­˜æ”¾å€ â”£â” fine_tune.ipynb jupyterè¨“ç·´è…³æœ¬ â”—â” huggingface_token huggingfaceré‡‘é‘° å®‰è£ cuda cuda wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run sudo sh cuda_11.4.0_470.42.01_linux.run å¦‚æœè¦ç¨ç«‹è£ driverï¼Œå°±æŠŠ driver å–æ¶ˆ\ndriver sudo apt-get install nvidia-driver-470 Huggingface é‡‘é‘°ç”³è«‹ è«‹åˆ°huggingface å®˜ç¶² å³ä¸Šçš„é¸é … â†’ Settings â†’ Access Tokens é»é¸New tokenï¼ŒNameè‡ªè¨‚ï¼ŒRoleé¸write Generate a tokenå¾Œï¼Œå°‡ç”¢ç”Ÿçš„tokenè¤‡è£½è²¼ä¸Šåˆ°å°ˆæ¡ˆçš„huggingface_token\nç¨‹å¼ç¢¼èªªæ˜ å»ºç«‹æ¨¡å‹åç¨± è«‹è¼¸å…¥æª”æ¡ˆåç¨±\n1 model_name='model name' ç™»å…¥ hugging face å°‡è¨“ç·´å®Œæˆçš„æ¨¡å‹ä¸Šå‚³åˆ°å­˜æ”¾åœ¨ huggingfaceï¼Œå¯ä»¥æ¸›å°‘æœ¬åœ°ç«¯ç©ºé–“å ç”¨ã€‚ Tokenè«‹è‡ªè¡Œå» huggingface ç”³è«‹\n1 2 3 from huggingface_hub.hf_api import HfFolder token=open('huggingface_token','r').readlines()[0].split('\\n')[0] HfFolder.save_token(token) è¼‰å…¥éŸ³æª”è³‡æ–™ æœƒå¾data_diråº•ä¸‹æ‹‰èªæ–™é€²è¡Œä½¿ç”¨\n1 2 3 4 from datasets import load_dataset common_voice = load_dataset(\"./\", data_dir=\"audio\",use_auth_token=True) # å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼æŸ¥çœ‹datasetçµæ§‹ print(common_voice) è¼‰å…¥ Openai å»ºç«‹å¥½çš„æ¨¡å‹ ä½¿ç”¨ openai æä¾›çš„åŸºç¤æ¨¡å‹ï¼Œæ¨¡å‹å¤§å°æˆ–èªè¨€ï¼Œè«‹è‡ªè¡Œæ›´æ›\n1 2 3 4 from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\") tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"zh\", task=\"transcribe\") processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"zh\", task=\"transcribe\") èªæ–™è½‰æ›å–æ¨£ç‡ éŸ³æª”å–æ¨£ç‡è½‰æ›æˆ 16000HkHz\n1 2 3 4 5 6 7 8 9 10 from datasets import Audio common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000)) def prepare_dataset(batch): audio = batch[\"audio\"] batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0] batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids return batch common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=2) data_collator 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import torch from dataclasses import dataclass from typing import Any, Dict, List, Union @dataclass class DataCollatorSpeechSeq2SeqWithPadding: processor: Any def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -\u003e Dict[str, torch.Tensor]: # split inputs and labels since they have to be of different lengths and need different padding methods # first treat the audio inputs by simply returning torch tensors input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features] batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\") # get the tokenized label sequences label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features] # pad the labels to max length labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\") # replace padding with -100 to ignore loss correctly labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100) # if bos token is appended in previous tokenization step, # cut bos token here as it's append later anyways if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item(): labels = labels[:, 1:] batch[\"labels\"] = labels return batch data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor) compute_metrics è¨ˆç®— CER(æˆ– WER)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import evaluate metric = evaluate.load(\"cer\") def compute_metrics(pred): pred_ids = pred.predictions label_ids = pred.label_ids # replace -100 with the pad_token_id label_ids[label_ids == -100] = tokenizer.pad_token_id # we do not want to group tokens when computing the metrics pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True) label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True) cer = 100 * metric.compute(predictions=pred_str, references=label_str) return {\"cer\": cer} model 1 2 3 4 5 from transformers import WhisperForConditionalGeneration model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\") model.config.forced_decoder_ids = None model.config.suppress_tokens = [] training_args 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from transformers import Seq2SeqTrainingArguments training_args = Seq2SeqTrainingArguments( output_dir=\"./model_name\", # æ¨¡å‹åç¨±ï¼Œä½ éœ€è¦æ›´æ”¹ per_device_train_batch_size=16, # æ‰¹æ¬¡å¤§å°ï¼Œä½ å¯èƒ½æœƒéœ€è¦èª¿æ•´ gradient_accumulation_steps=1, learning_rate=1e-5, # å­¸ç¿’ç‡ï¼Œä½ å¯èƒ½æœƒéœ€è¦èª¿æ•´ warmup_steps=500, max_steps=4000, # è¨“ç·´æ¬¡æ•¸ï¼Œä½ å¯èƒ½æœƒéœ€è¦èª¿æ•´ gradient_checkpointing=True, fp16=True, evaluation_strategy=\"steps\", per_device_eval_batch_size=8, predict_with_generate=True, generation_max_length=225, save_steps=1000, eval_steps=1000, logging_steps=25, report_to=[\"tensorboard\"], load_best_model_at_end=True, metric_for_best_model=\"cer\", greater_is_better=False, push_to_hub=True, ) trainer 1 2 3 4 5 6 7 8 9 10 11 12 13 from transformers import Seq2SeqTrainer trainer = Seq2SeqTrainer( args=training_args, model=model, train_dataset=common_voice[\"train\"], eval_dataset=common_voice[\"test\"], data_collator=data_collator, compute_metrics=compute_metrics, tokenizer=processor.feature_extractor, ) processor.save_pretrained(training_args.output_dir) é–‹å§‹è¨“ç·´ 1 trainer.train() å¾æœ¬åœ°ä¸Šå‚³æ¨¡å‹åˆ° HuggingFace 1 2 3 4 5 6 7 8 9 10 11 12 kwargs = { \"dataset_tags\": \"-\", \"dataset\": \"some hakka audio\", # è¼¸å…¥è³‡æ–™åŠåç¨± \"dataset_args\": \"config: zh, split: test\", \"language\": \"zh\", \"model_name\": \"a name\", # è¼¸å…¥æ¨¡å‹åç¨± \"finetuned_from\": \"openai/whisper-base\", # åŸºç¤æ¨¡å‹ \"tasks\": \"automatic-speech-recognition\", \"tags\": \"whisper\", } trainer.push_to_hub(**kwargs) å¾ HuggingFace ä¸‹è¼‰æ¨¡å‹ ä½ éœ€è¦æ›´æ”¹è¦ä¸‹è¼‰ model çš„ä½ç½®èˆ‡å­˜æ”¾ä½ç½®\n1 2 3 4 5 6 from multiple_datasets.hub_default_utils import convert_hf_whisper model_name_or_path = 'model_name_on_hugging_face' whisper_checkpoint_path = 'save_model_path' convert_hf_whisper(model_name_or_path, whisper_checkpoint_path) reference https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb#scrollTo=810ced54-7187-4a06-b2fe-ba6dcca94dc3 https://colab.research.google.com/drive/1RkboArXsuXIEDTE5OHfJe-0Gn7v3gXI1?usp=sharing#scrollTo=-hxbi4vVPpoy https://wandb.ai/parambharat/whisper_finetuning/reports/Fine-tuning-Whisper-ASR-models---VmlldzozMTEzNDE5 https://huggingface.co/jlondonobo/whisper-medium-pt https://github.com/bayartsogt-ya/whisper-multiple-hf-datasets https://github.com/luigisaetta/whisper-app/blob/main/match_layers.ipynb https://www.mlq.ai/openai-whisper-gpt-3-fine-tuning-youtube-video/ https://stackoverflow.com/questions/71561761/how-to-load-a-fine-tuned-pytorch-huggingface-bert-model-from-a-checkpoint-file https://colab.research.google.com/drive/1P4ClLkPmfsaKn2tBbRp0nVjGMRKR-EWz https://huggingface.co/spaces/openai/whisper/discussions/6 https://huggingface.co/blog/fine-tune-whisper https://github.com/openai/whisper/discussions/98\n","wordCount":"625","inLanguage":"en","datePublished":"2023-07-04T09:42:49Z","dateModified":"2023-07-04T09:42:49Z","author":{"@type":"Person","name":"Aura"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://aura.codex.tw/posts/openai-whisper-fine-tuning-hakka/"},"publisher":{"@type":"Organization","name":"Aura's Space","logo":{"@type":"ImageObject","url":"https://aura.codex.tw/images/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://aura.codex.tw/ accesskey=h title="Aura's Space (Alt + H)"><img src=https://aura.codex.tw/images/favicon.ico alt aria-label=logo height=35>Aura's Space</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://aura.codex.tw/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://aura.codex.tw/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://aura.codex.tw/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://aura.codex.tw/about/ title=About><span>About</span></a></li><li><a href=https://aura.codex.tw/search/ title="ğŸ” (Alt + /)" accesskey=/><span>ğŸ”</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://aura.codex.tw/>Home</a>&nbsp;Â»&nbsp;<a href=https://aura.codex.tw/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Openai Whisper Fine-Tuning - Hakka</h1><div class=post-meta><span title='2023-07-04 09:42:49 +0000 UTC'>July 4, 2023</span>&nbsp;Â·&nbsp;<span>3 min</span>&nbsp;Â·&nbsp;<span>Aura</span></div></header><ul class=post-tags></ul><div class=post-content><h1 id=é€£çµ>é€£çµ<a hidden class=anchor aria-hidden=true href=#é€£çµ>#</a></h1><p><a href=https://github.com/AU2A/whisper_finetuning>Github</a></p><h1 id=é‡é»å°ˆæ¡ˆçµæ§‹>é‡é»å°ˆæ¡ˆçµæ§‹<a hidden class=anchor aria-hidden=true href=#é‡é»å°ˆæ¡ˆçµæ§‹>#</a></h1><pre tabindex=0><code>whisper_hakka
 â”—â”³â” audio
  â”ƒ   â”£â” test
  â”ƒ   â”ƒ   â”—â” testèªæ–™å­˜æ”¾å€
  â”ƒ   â”£â” train
  â”ƒ   â”ƒ   â”—â” trainèªæ–™å­˜æ”¾å€
  â”ƒ   â”—â” metadata.csv æª”æ¡ˆè·¯å¾‘èˆ‡æ–‡æœ¬å…§å®¹
  â”£â” model
  â”ƒ   â”—â” æ¨¡å‹å­˜æ”¾å€
  â”£â” fine_tune.ipynb jupyterè¨“ç·´è…³æœ¬
  â”—â” huggingface_token huggingfaceré‡‘é‘°
</code></pre><h1 id=å®‰è£-cuda>å®‰è£ cuda<a hidden class=anchor aria-hidden=true href=#å®‰è£-cuda>#</a></h1><h4 id=cuda>cuda<a hidden class=anchor aria-hidden=true href=#cuda>#</a></h4><pre tabindex=0><code>wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run
sudo sh cuda_11.4.0_470.42.01_linux.run
</code></pre><p>å¦‚æœè¦ç¨ç«‹è£ driverï¼Œå°±æŠŠ driver å–æ¶ˆ</p><h4 id=driver>driver<a hidden class=anchor aria-hidden=true href=#driver>#</a></h4><pre tabindex=0><code>sudo apt-get install nvidia-driver-470
</code></pre><h1 id=huggingface-é‡‘é‘°ç”³è«‹>Huggingface é‡‘é‘°ç”³è«‹<a hidden class=anchor aria-hidden=true href=#huggingface-é‡‘é‘°ç”³è«‹>#</a></h1><p>è«‹åˆ°<a href=https://huggingface.co/>huggingface å®˜ç¶²</a>
å³ä¸Šçš„é¸é … â†’ <code>Settings</code> â†’ <code>Access Tokens</code>
é»é¸<code>New token</code>ï¼Œ<code>Name</code>è‡ªè¨‚ï¼Œ<code>Role</code>é¸<code>write</code>
<code>Generate a token</code>å¾Œï¼Œå°‡ç”¢ç”Ÿçš„<code>token</code>è¤‡è£½è²¼ä¸Šåˆ°å°ˆæ¡ˆçš„<code>huggingface_token</code></p><h1 id=ç¨‹å¼ç¢¼èªªæ˜>ç¨‹å¼ç¢¼èªªæ˜<a hidden class=anchor aria-hidden=true href=#ç¨‹å¼ç¢¼èªªæ˜>#</a></h1><h4 id=å»ºç«‹æ¨¡å‹åç¨±>å»ºç«‹æ¨¡å‹åç¨±<a hidden class=anchor aria-hidden=true href=#å»ºç«‹æ¨¡å‹åç¨±>#</a></h4><p>è«‹è¼¸å…¥æª”æ¡ˆåç¨±</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=n>model_name</span><span class=o>=</span><span class=s1>&#39;model name&#39;</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=ç™»å…¥-hugging-face>ç™»å…¥ hugging face<a hidden class=anchor aria-hidden=true href=#ç™»å…¥-hugging-face>#</a></h4><p>å°‡è¨“ç·´å®Œæˆçš„æ¨¡å‹ä¸Šå‚³åˆ°å­˜æ”¾åœ¨ huggingfaceï¼Œå¯ä»¥æ¸›å°‘æœ¬åœ°ç«¯ç©ºé–“å ç”¨ã€‚
<code>Token</code>è«‹è‡ªè¡Œå» huggingface ç”³è«‹</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>huggingface_hub.hf_api</span> <span class=kn>import</span> <span class=n>HfFolder</span>
</span></span><span class=line><span class=cl><span class=n>token</span><span class=o>=</span><span class=nb>open</span><span class=p>(</span><span class=s1>&#39;huggingface_token&#39;</span><span class=p>,</span><span class=s1>&#39;r&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>readlines</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>HfFolder</span><span class=o>.</span><span class=n>save_token</span><span class=p>(</span><span class=n>token</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=è¼‰å…¥éŸ³æª”è³‡æ–™>è¼‰å…¥éŸ³æª”è³‡æ–™<a hidden class=anchor aria-hidden=true href=#è¼‰å…¥éŸ³æª”è³‡æ–™>#</a></h4><p>æœƒå¾<code>data_dir</code>åº•ä¸‹æ‹‰èªæ–™é€²è¡Œä½¿ç”¨</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
</span></span><span class=line><span class=cl><span class=n>common_voice</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;./&#34;</span><span class=p>,</span> <span class=n>data_dir</span><span class=o>=</span><span class=s2>&#34;audio&#34;</span><span class=p>,</span><span class=n>use_auth_token</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼æŸ¥çœ‹datasetçµæ§‹</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>common_voice</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=è¼‰å…¥-openai-å»ºç«‹å¥½çš„æ¨¡å‹>è¼‰å…¥ Openai å»ºç«‹å¥½çš„æ¨¡å‹<a hidden class=anchor aria-hidden=true href=#è¼‰å…¥-openai-å»ºç«‹å¥½çš„æ¨¡å‹>#</a></h4><p>ä½¿ç”¨ openai æä¾›çš„åŸºç¤æ¨¡å‹ï¼Œæ¨¡å‹å¤§å°æˆ–èªè¨€ï¼Œè«‹è‡ªè¡Œæ›´æ›</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>WhisperFeatureExtractor</span><span class=p>,</span> <span class=n>WhisperTokenizer</span><span class=p>,</span> <span class=n>WhisperProcessor</span>
</span></span><span class=line><span class=cl><span class=n>feature_extractor</span> <span class=o>=</span> <span class=n>WhisperFeatureExtractor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;openai/whisper-base&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>WhisperTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;openai/whisper-base&#34;</span><span class=p>,</span> <span class=n>language</span><span class=o>=</span><span class=s2>&#34;zh&#34;</span><span class=p>,</span> <span class=n>task</span><span class=o>=</span><span class=s2>&#34;transcribe&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>WhisperProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;openai/whisper-base&#34;</span><span class=p>,</span> <span class=n>language</span><span class=o>=</span><span class=s2>&#34;zh&#34;</span><span class=p>,</span> <span class=n>task</span><span class=o>=</span><span class=s2>&#34;transcribe&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=èªæ–™è½‰æ›å–æ¨£ç‡>èªæ–™è½‰æ›å–æ¨£ç‡<a hidden class=anchor aria-hidden=true href=#èªæ–™è½‰æ›å–æ¨£ç‡>#</a></h4><p>éŸ³æª”å–æ¨£ç‡è½‰æ›æˆ 16000HkHz</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>Audio</span>
</span></span><span class=line><span class=cl><span class=n>common_voice</span> <span class=o>=</span> <span class=n>common_voice</span><span class=o>.</span><span class=n>cast_column</span><span class=p>(</span><span class=s2>&#34;audio&#34;</span><span class=p>,</span> <span class=n>Audio</span><span class=p>(</span><span class=n>sampling_rate</span><span class=o>=</span><span class=mi>16000</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>prepare_dataset</span><span class=p>(</span><span class=n>batch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>audio</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=s2>&#34;audio&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=p>[</span><span class=s2>&#34;input_features&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>feature_extractor</span><span class=p>(</span><span class=n>audio</span><span class=p>[</span><span class=s2>&#34;array&#34;</span><span class=p>],</span> <span class=n>sampling_rate</span><span class=o>=</span><span class=n>audio</span><span class=p>[</span><span class=s2>&#34;sampling_rate&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>input_features</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=p>[</span><span class=s2>&#34;labels&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;sentence&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>input_ids</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>batch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>common_voice</span> <span class=o>=</span> <span class=n>common_voice</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>prepare_dataset</span><span class=p>,</span> <span class=n>remove_columns</span><span class=o>=</span><span class=n>common_voice</span><span class=o>.</span><span class=n>column_names</span><span class=p>[</span><span class=s2>&#34;train&#34;</span><span class=p>],</span> <span class=n>num_proc</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=data_collator>data_collator<a hidden class=anchor aria-hidden=true href=#data_collator>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Any</span><span class=p>,</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>List</span><span class=p>,</span> <span class=n>Union</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataCollatorSpeechSeq2SeqWithPadding</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>processor</span><span class=p>:</span> <span class=n>Any</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>features</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Union</span><span class=p>[</span><span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>],</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]]])</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=c1># split inputs and labels since they have to be of different lengths and need different padding methods</span>
</span></span><span class=line><span class=cl>        <span class=c1># first treat the audio inputs by simply returning torch tensors</span>
</span></span><span class=line><span class=cl>        <span class=n>input_features</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&#34;input_features&#34;</span><span class=p>:</span> <span class=n>feature</span><span class=p>[</span><span class=s2>&#34;input_features&#34;</span><span class=p>]}</span> <span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>features</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>feature_extractor</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span><span class=n>input_features</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># get the tokenized label sequences</span>
</span></span><span class=line><span class=cl>        <span class=n>label_features</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=n>feature</span><span class=p>[</span><span class=s2>&#34;labels&#34;</span><span class=p>]}</span> <span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>features</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># pad the labels to max length</span>
</span></span><span class=line><span class=cl>        <span class=n>labels_batch</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span><span class=n>label_features</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># replace padding with -100 to ignore loss correctly</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=n>labels_batch</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>labels_batch</span><span class=o>.</span><span class=n>attention_mask</span><span class=o>.</span><span class=n>ne</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=o>-</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># if bos token is appended in previous tokenization step,</span>
</span></span><span class=line><span class=cl>        <span class=c1># cut bos token here as it&#39;s append later anyways</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>labels</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>bos_token_id</span><span class=p>)</span><span class=o>.</span><span class=n>all</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>labels</span> <span class=o>=</span> <span class=n>labels</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=p>[</span><span class=s2>&#34;labels&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>labels</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>batch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data_collator</span> <span class=o>=</span> <span class=n>DataCollatorSpeechSeq2SeqWithPadding</span><span class=p>(</span><span class=n>processor</span><span class=o>=</span><span class=n>processor</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=compute_metrics>compute_metrics<a hidden class=anchor aria-hidden=true href=#compute_metrics>#</a></h4><p>è¨ˆç®— CER(æˆ– WER)</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>evaluate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>metric</span> <span class=o>=</span> <span class=n>evaluate</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&#34;cer&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_metrics</span><span class=p>(</span><span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>pred_ids</span> <span class=o>=</span> <span class=n>pred</span><span class=o>.</span><span class=n>predictions</span>
</span></span><span class=line><span class=cl>    <span class=n>label_ids</span> <span class=o>=</span> <span class=n>pred</span><span class=o>.</span><span class=n>label_ids</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># replace -100 with the pad_token_id</span>
</span></span><span class=line><span class=cl>    <span class=n>label_ids</span><span class=p>[</span><span class=n>label_ids</span> <span class=o>==</span> <span class=o>-</span><span class=mi>100</span><span class=p>]</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># we do not want to group tokens when computing the metrics</span>
</span></span><span class=line><span class=cl>    <span class=n>pred_str</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>pred_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>label_str</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>label_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cer</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>pred_str</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>label_str</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;cer&#34;</span><span class=p>:</span> <span class=n>cer</span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=model>model<a hidden class=anchor aria-hidden=true href=#model>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>WhisperForConditionalGeneration</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>WhisperForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;openai/whisper-base&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>forced_decoder_ids</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>suppress_tokens</span> <span class=o>=</span> <span class=p>[]</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=training_args>training_args<a hidden class=anchor aria-hidden=true href=#training_args>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>Seq2SeqTrainingArguments</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>training_args</span> <span class=o>=</span> <span class=n>Seq2SeqTrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&#34;./model_name&#34;</span><span class=p>,</span> <span class=c1># æ¨¡å‹åç¨±ï¼Œä½ éœ€è¦æ›´æ”¹</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span> <span class=c1># æ‰¹æ¬¡å¤§å°ï¼Œä½ å¯èƒ½æœƒéœ€è¦èª¿æ•´</span>
</span></span><span class=line><span class=cl>    <span class=n>gradient_accumulation_steps</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>learning_rate</span><span class=o>=</span><span class=mf>1e-5</span><span class=p>,</span> <span class=c1># å­¸ç¿’ç‡ï¼Œä½ å¯èƒ½æœƒéœ€è¦èª¿æ•´</span>
</span></span><span class=line><span class=cl>    <span class=n>warmup_steps</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_steps</span><span class=o>=</span><span class=mi>4000</span><span class=p>,</span> <span class=c1># è¨“ç·´æ¬¡æ•¸ï¼Œä½ å¯èƒ½æœƒéœ€è¦èª¿æ•´</span>
</span></span><span class=line><span class=cl>    <span class=n>gradient_checkpointing</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>fp16</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluation_strategy</span><span class=o>=</span><span class=s2>&#34;steps&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>predict_with_generate</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>generation_max_length</span><span class=o>=</span><span class=mi>225</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>logging_steps</span><span class=o>=</span><span class=mi>25</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>report_to</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;tensorboard&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>load_best_model_at_end</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>metric_for_best_model</span><span class=o>=</span><span class=s2>&#34;cer&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>greater_is_better</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>push_to_hub</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=trainer>trainer<a hidden class=anchor aria-hidden=true href=#trainer>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>Seq2SeqTrainer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>Seq2SeqTrainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>common_voice</span><span class=p>[</span><span class=s2>&#34;train&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>common_voice</span><span class=p>[</span><span class=s2>&#34;test&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>data_collator</span><span class=o>=</span><span class=n>data_collator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>processor</span><span class=o>.</span><span class=n>feature_extractor</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processor</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=é–‹å§‹è¨“ç·´>é–‹å§‹è¨“ç·´<a hidden class=anchor aria-hidden=true href=#é–‹å§‹è¨“ç·´>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=å¾æœ¬åœ°ä¸Šå‚³æ¨¡å‹åˆ°-huggingface>å¾æœ¬åœ°ä¸Šå‚³æ¨¡å‹åˆ° HuggingFace<a hidden class=anchor aria-hidden=true href=#å¾æœ¬åœ°ä¸Šå‚³æ¨¡å‹åˆ°-huggingface>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=n>kwargs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;dataset_tags&#34;</span><span class=p>:</span> <span class=s2>&#34;-&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;dataset&#34;</span><span class=p>:</span> <span class=s2>&#34;some hakka audio&#34;</span><span class=p>,</span>  <span class=c1># è¼¸å…¥è³‡æ–™åŠåç¨±</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;dataset_args&#34;</span><span class=p>:</span> <span class=s2>&#34;config: zh, split: test&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;language&#34;</span><span class=p>:</span> <span class=s2>&#34;zh&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;model_name&#34;</span><span class=p>:</span> <span class=s2>&#34;a name&#34;</span><span class=p>,</span>  <span class=c1># è¼¸å…¥æ¨¡å‹åç¨±</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;finetuned_from&#34;</span><span class=p>:</span> <span class=s2>&#34;openai/whisper-base&#34;</span><span class=p>,</span> <span class=c1># åŸºç¤æ¨¡å‹</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;tasks&#34;</span><span class=p>:</span> <span class=s2>&#34;automatic-speech-recognition&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;tags&#34;</span><span class=p>:</span> <span class=s2>&#34;whisper&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>push_to_hub</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=å¾-huggingface-ä¸‹è¼‰æ¨¡å‹>å¾ HuggingFace ä¸‹è¼‰æ¨¡å‹<a hidden class=anchor aria-hidden=true href=#å¾-huggingface-ä¸‹è¼‰æ¨¡å‹>#</a></h4><p>ä½ éœ€è¦æ›´æ”¹è¦ä¸‹è¼‰ model çš„ä½ç½®èˆ‡å­˜æ”¾ä½ç½®</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>multiple_datasets.hub_default_utils</span> <span class=kn>import</span> <span class=n>convert_hf_whisper</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_name_or_path</span> <span class=o>=</span> <span class=s1>&#39;model_name_on_hugging_face&#39;</span>
</span></span><span class=line><span class=cl><span class=n>whisper_checkpoint_path</span> <span class=o>=</span> <span class=s1>&#39;save_model_path&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>convert_hf_whisper</span><span class=p>(</span><span class=n>model_name_or_path</span><span class=p>,</span> <span class=n>whisper_checkpoint_path</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=reference>reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h1><p><a href="https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb#scrollTo=810ced54-7187-4a06-b2fe-ba6dcca94dc3">https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb#scrollTo=810ced54-7187-4a06-b2fe-ba6dcca94dc3</a>
<a href="https://colab.research.google.com/drive/1RkboArXsuXIEDTE5OHfJe-0Gn7v3gXI1?usp=sharing#scrollTo=-hxbi4vVPpoy">https://colab.research.google.com/drive/1RkboArXsuXIEDTE5OHfJe-0Gn7v3gXI1?usp=sharing#scrollTo=-hxbi4vVPpoy</a>
<a href=https://wandb.ai/parambharat/whisper_finetuning/reports/Fine-tuning-Whisper-ASR-models---VmlldzozMTEzNDE5>https://wandb.ai/parambharat/whisper_finetuning/reports/Fine-tuning-Whisper-ASR-models---VmlldzozMTEzNDE5</a>
<a href=https://huggingface.co/jlondonobo/whisper-medium-pt>https://huggingface.co/jlondonobo/whisper-medium-pt</a>
<a href=https://github.com/bayartsogt-ya/whisper-multiple-hf-datasets>https://github.com/bayartsogt-ya/whisper-multiple-hf-datasets</a>
<a href=https://github.com/luigisaetta/whisper-app/blob/main/match_layers.ipynb>https://github.com/luigisaetta/whisper-app/blob/main/match_layers.ipynb</a>
<a href=https://www.mlq.ai/openai-whisper-gpt-3-fine-tuning-youtube-video/>https://www.mlq.ai/openai-whisper-gpt-3-fine-tuning-youtube-video/</a>
<a href=https://stackoverflow.com/questions/71561761/how-to-load-a-fine-tuned-pytorch-huggingface-bert-model-from-a-checkpoint-file>https://stackoverflow.com/questions/71561761/how-to-load-a-fine-tuned-pytorch-huggingface-bert-model-from-a-checkpoint-file</a>
<a href=https://colab.research.google.com/drive/1P4ClLkPmfsaKn2tBbRp0nVjGMRKR-EWz>https://colab.research.google.com/drive/1P4ClLkPmfsaKn2tBbRp0nVjGMRKR-EWz</a>
<a href=https://huggingface.co/spaces/openai/whisper/discussions/6>https://huggingface.co/spaces/openai/whisper/discussions/6</a>
<a href=https://huggingface.co/blog/fine-tune-whisper>https://huggingface.co/blog/fine-tune-whisper</a>
<a href=https://github.com/openai/whisper/discussions/98>https://github.com/openai/whisper/discussions/98</a></p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022~2025 <a href=https://aura.codex.tw/>Aura's Space</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>