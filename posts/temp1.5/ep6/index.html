<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>【Temperature 1.5 的日常】EP6: LangChain - Built-in Middleware, 打造 AI 的全能工具箱 | Aura's Space</title><meta name=keywords content="LangChain,Python"><meta name=description content="

本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。


零、 前言
接續上次我們聊到的 Human-in-the-Loop (HITL)，我們知道為了安全，必須在 AI 動手前加個「緊急煞車」。但開發一個生產等級的 Agent，光有煞車是不夠的，你可能還需要一個自動清理垃圾的清潔員、一個幫你省錢的會計師，甚至是一個能在主線掛掉時自動接手的備援司機。
在 LangChain 的世界裡，這些功能不必從零開始寫。官方提供了一整套「內建中介軟體」（Built-in Middleware），它們就像是 Agent 的各種外掛模組，插上去就能用。今天我們就來開箱這個萬能工具箱。

一、 什麼是內建中介軟體？
簡單來說，中介軟體（Middleware）是介於「使用者輸入」與「模型回應」之間的邏輯層。LangChain 的內建中介軟體已經針對常見的 Agent 使用場景進行了最佳化，且大部份是 Provider-agnostic（與供應商無關），無論你底層用的是 OpenAI、Anthropic 還是本地的 Llama，通通適用。
以下是目前官方提供的核心中介軟體清單：

  
      
          中介軟體
          主要功能
      
  
  
      
          Summarization
          當 Token 接近上限時，自動摘要對話歷史。
      
      
          Model/Tool Call Limit
          限制模型或工具的調用次數，防止成本失控。
      
      
          Model Fallback
          主模型失效時，自動切換到備援模型。
      
      
          PII Detection
          偵測並處理個人敏感資訊（如姓名、信用卡號）。
      
      
          Tool/Model Retry
          遇到暫時性錯誤時，自動進行指數退避重試。
      
      
          Context Editing
          精細管理上下文，例如清除舊的工具輸出。
      
      
          Shell / File Search
          提供持久的 Shell 環境或檔案搜尋能力。
      
  


二、 Token 的管理大師：Summarization & Context Editing
AI 最怕的就是「忘東忘西」或是「話太多」導致 Token 爆量。
1. Summarization Middleware
當對話變長時，這個中介軟體會自動觸發。它會保留最近的幾則訊息，並將更早之前的對話壓縮成一段摘要。"><meta name=author content="Aura"><link rel=canonical href=https://aura.codex.tw/posts/temp1.5/ep6/><link crossorigin=anonymous href=/assets/css/stylesheet.0a190288459736d4d10e13cb6ee8068b9aa282b3f8938264b3b2d6a98bf701b7.css integrity="sha256-ChkCiEWXNtTRDhPLbugGi5qigrP4k4Jks7LWqYv3Abc=" rel="preload stylesheet" as=style><link rel=icon href=https://aura.codex.tw/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://aura.codex.tw/images/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://aura.codex.tw/images/favicon.ico><link rel=apple-touch-icon href=https://aura.codex.tw/images/favicon.ico><link rel=mask-icon href=https://aura.codex.tw/images/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://aura.codex.tw/posts/temp1.5/ep6/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://aura.codex.tw/posts/temp1.5/ep6/"><meta property="og:site_name" content="Aura's Space"><meta property="og:title" content="【Temperature 1.5 的日常】EP6: LangChain - Built-in Middleware, 打造 AI 的全能工具箱"><meta property="og:description" content=" 本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。
零、 前言 接續上次我們聊到的 Human-in-the-Loop (HITL)，我們知道為了安全，必須在 AI 動手前加個「緊急煞車」。但開發一個生產等級的 Agent，光有煞車是不夠的，你可能還需要一個自動清理垃圾的清潔員、一個幫你省錢的會計師，甚至是一個能在主線掛掉時自動接手的備援司機。
在 LangChain 的世界裡，這些功能不必從零開始寫。官方提供了一整套「內建中介軟體」（Built-in Middleware），它們就像是 Agent 的各種外掛模組，插上去就能用。今天我們就來開箱這個萬能工具箱。
一、 什麼是內建中介軟體？ 簡單來說，中介軟體（Middleware）是介於「使用者輸入」與「模型回應」之間的邏輯層。LangChain 的內建中介軟體已經針對常見的 Agent 使用場景進行了最佳化，且大部份是 Provider-agnostic（與供應商無關），無論你底層用的是 OpenAI、Anthropic 還是本地的 Llama，通通適用。
以下是目前官方提供的核心中介軟體清單：
中介軟體 主要功能 Summarization 當 Token 接近上限時，自動摘要對話歷史。 Model/Tool Call Limit 限制模型或工具的調用次數，防止成本失控。 Model Fallback 主模型失效時，自動切換到備援模型。 PII Detection 偵測並處理個人敏感資訊（如姓名、信用卡號）。 Tool/Model Retry 遇到暫時性錯誤時，自動進行指數退避重試。 Context Editing 精細管理上下文，例如清除舊的工具輸出。 Shell / File Search 提供持久的 Shell 環境或檔案搜尋能力。 二、 Token 的管理大師：Summarization & Context Editing AI 最怕的就是「忘東忘西」或是「話太多」導致 Token 爆量。
1. Summarization Middleware 當對話變長時，這個中介軟體會自動觸發。它會保留最近的幾則訊息，並將更早之前的對話壓縮成一段摘要。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-20T00:00:00+00:00"><meta property="article:modified_time" content="2025-10-20T00:00:00+00:00"><meta property="article:tag" content="LangChain"><meta property="article:tag" content="Python"><meta name=twitter:card content="summary"><meta name=twitter:title content="【Temperature 1.5 的日常】EP6: LangChain - Built-in Middleware, 打造 AI 的全能工具箱"><meta name=twitter:description content="

本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。


零、 前言
接續上次我們聊到的 Human-in-the-Loop (HITL)，我們知道為了安全，必須在 AI 動手前加個「緊急煞車」。但開發一個生產等級的 Agent，光有煞車是不夠的，你可能還需要一個自動清理垃圾的清潔員、一個幫你省錢的會計師，甚至是一個能在主線掛掉時自動接手的備援司機。
在 LangChain 的世界裡，這些功能不必從零開始寫。官方提供了一整套「內建中介軟體」（Built-in Middleware），它們就像是 Agent 的各種外掛模組，插上去就能用。今天我們就來開箱這個萬能工具箱。

一、 什麼是內建中介軟體？
簡單來說，中介軟體（Middleware）是介於「使用者輸入」與「模型回應」之間的邏輯層。LangChain 的內建中介軟體已經針對常見的 Agent 使用場景進行了最佳化，且大部份是 Provider-agnostic（與供應商無關），無論你底層用的是 OpenAI、Anthropic 還是本地的 Llama，通通適用。
以下是目前官方提供的核心中介軟體清單：

  
      
          中介軟體
          主要功能
      
  
  
      
          Summarization
          當 Token 接近上限時，自動摘要對話歷史。
      
      
          Model/Tool Call Limit
          限制模型或工具的調用次數，防止成本失控。
      
      
          Model Fallback
          主模型失效時，自動切換到備援模型。
      
      
          PII Detection
          偵測並處理個人敏感資訊（如姓名、信用卡號）。
      
      
          Tool/Model Retry
          遇到暫時性錯誤時，自動進行指數退避重試。
      
      
          Context Editing
          精細管理上下文，例如清除舊的工具輸出。
      
      
          Shell / File Search
          提供持久的 Shell 環境或檔案搜尋能力。
      
  


二、 Token 的管理大師：Summarization & Context Editing
AI 最怕的就是「忘東忘西」或是「話太多」導致 Token 爆量。
1. Summarization Middleware
當對話變長時，這個中介軟體會自動觸發。它會保留最近的幾則訊息，並將更早之前的對話壓縮成一段摘要。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://aura.codex.tw/posts/"},{"@type":"ListItem","position":2,"name":"【Temperature 1.5 的日常】EP6: LangChain - Built-in Middleware, 打造 AI 的全能工具箱","item":"https://aura.codex.tw/posts/temp1.5/ep6/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"【Temperature 1.5 的日常】EP6: LangChain - Built-in Middleware, 打造 AI 的全能工具箱","name":"【Temperature 1.5 的日常】EP6: LangChain - Built-in Middleware, 打造 AI 的全能工具箱","description":" 本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。\n零、 前言 接續上次我們聊到的 Human-in-the-Loop (HITL)，我們知道為了安全，必須在 AI 動手前加個「緊急煞車」。但開發一個生產等級的 Agent，光有煞車是不夠的，你可能還需要一個自動清理垃圾的清潔員、一個幫你省錢的會計師，甚至是一個能在主線掛掉時自動接手的備援司機。\n在 LangChain 的世界裡，這些功能不必從零開始寫。官方提供了一整套「內建中介軟體」（Built-in Middleware），它們就像是 Agent 的各種外掛模組，插上去就能用。今天我們就來開箱這個萬能工具箱。\n一、 什麼是內建中介軟體？ 簡單來說，中介軟體（Middleware）是介於「使用者輸入」與「模型回應」之間的邏輯層。LangChain 的內建中介軟體已經針對常見的 Agent 使用場景進行了最佳化，且大部份是 Provider-agnostic（與供應商無關），無論你底層用的是 OpenAI、Anthropic 還是本地的 Llama，通通適用。\n以下是目前官方提供的核心中介軟體清單：\n中介軟體 主要功能 Summarization 當 Token 接近上限時，自動摘要對話歷史。 Model/Tool Call Limit 限制模型或工具的調用次數，防止成本失控。 Model Fallback 主模型失效時，自動切換到備援模型。 PII Detection 偵測並處理個人敏感資訊（如姓名、信用卡號）。 Tool/Model Retry 遇到暫時性錯誤時，自動進行指數退避重試。 Context Editing 精細管理上下文，例如清除舊的工具輸出。 Shell / File Search 提供持久的 Shell 環境或檔案搜尋能力。 二、 Token 的管理大師：Summarization \u0026amp; Context Editing AI 最怕的就是「忘東忘西」或是「話太多」導致 Token 爆量。\n1. Summarization Middleware 當對話變長時，這個中介軟體會自動觸發。它會保留最近的幾則訊息，並將更早之前的對話壓縮成一段摘要。\n","keywords":["LangChain","Python"],"articleBody":" 本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。\n零、 前言 接續上次我們聊到的 Human-in-the-Loop (HITL)，我們知道為了安全，必須在 AI 動手前加個「緊急煞車」。但開發一個生產等級的 Agent，光有煞車是不夠的，你可能還需要一個自動清理垃圾的清潔員、一個幫你省錢的會計師，甚至是一個能在主線掛掉時自動接手的備援司機。\n在 LangChain 的世界裡，這些功能不必從零開始寫。官方提供了一整套「內建中介軟體」（Built-in Middleware），它們就像是 Agent 的各種外掛模組，插上去就能用。今天我們就來開箱這個萬能工具箱。\n一、 什麼是內建中介軟體？ 簡單來說，中介軟體（Middleware）是介於「使用者輸入」與「模型回應」之間的邏輯層。LangChain 的內建中介軟體已經針對常見的 Agent 使用場景進行了最佳化，且大部份是 Provider-agnostic（與供應商無關），無論你底層用的是 OpenAI、Anthropic 還是本地的 Llama，通通適用。\n以下是目前官方提供的核心中介軟體清單：\n中介軟體 主要功能 Summarization 當 Token 接近上限時，自動摘要對話歷史。 Model/Tool Call Limit 限制模型或工具的調用次數，防止成本失控。 Model Fallback 主模型失效時，自動切換到備援模型。 PII Detection 偵測並處理個人敏感資訊（如姓名、信用卡號）。 Tool/Model Retry 遇到暫時性錯誤時，自動進行指數退避重試。 Context Editing 精細管理上下文，例如清除舊的工具輸出。 Shell / File Search 提供持久的 Shell 環境或檔案搜尋能力。 二、 Token 的管理大師：Summarization \u0026 Context Editing AI 最怕的就是「忘東忘西」或是「話太多」導致 Token 爆量。\n1. Summarization Middleware 當對話變長時，這個中介軟體會自動觸發。它會保留最近的幾則訊息，並將更早之前的對話壓縮成一段摘要。\n觸發條件（Trigger）：可以設定 Token 數、訊息數量或模型上下文的比例（Fraction）。 保留內容（Keep）：指定摘要後要精確保留多少最近的對話。 2. Context Editing Middleware 這比摘要更暴力一點，它專門處理「工具輸出」。有時候工具回傳的資料量非常大，這個中介軟體可以在 Token 達到閾值時，直接清空舊的工具訊息，只留下最核心的 [cleared] 標記，確保模型不會因為無關的舊資料而混淆。\n三、 成本與風險的守門員：Call Limits 為了防止 Agent 陷入死循環（Runaway Agents），或是開發者一覺醒來欠了幾千美金的帳單，限制機制是必備的。\nModel Call Limit：限制單次運行（Run）或整個線程（Thread）的模型呼叫次數。 Tool Call Limit：可以針對特定工具（例如搜尋、資料庫）設定限制。當次數用完時，你可以選擇讓它報錯（error）或是優雅地結束（end）。 四、 韌性與容錯：Fallback \u0026 Retry 在分散式系統中，網路波動或 API 下線是常態。\nModel Fallback：你可以設定一個模型清單。如果 gpt-4o 壞了，自動切換到 claude-3-5-sonnet，確保服務不中斷。 Retry Middleware：這包含對工具和對模型的重試。它支援 指數退避（Exponential Backoff），這意味著它不會在失敗後立刻猛操 API，而是會越等越久（1 秒、2 秒、4 秒…），並加入隨機抖動（Jitter）來避免「驚群效應」。 五、 隱私守護：PII Detection 處理使用者資料時，合規性（Compliance）非常重要。PIIMiddleware 提供了四種處理策略：\nBlock：直接拋出異常。 Redact：用 [REDACTED_EMAIL] 取代。 Mask：部分遮蔽（如 ****-****-****-1234）。 Hash：轉換成不可逆的雜湊值。 除了內建的 Email、信用卡偵測，它也支援自定義的 Regex 或 偵測函數，讓你可以針對特定國家的身分證字號進行過濾。\n六、 賦予 AI 實質能力：Shell \u0026 File Search 有些中介軟體不只是「過濾器」，更是「賦能器」。\nShell Tool Middleware：這不是單純的一次性指令，它會為 Agent 提供一個 持久（Persistent） 的 Shell 會話。這意味著 Agent 可以在第一步 cd 進目錄，第二步 ls，狀態是會保留的。為了安全，它支援 Docker 隔離與輸出脫敏。 Filesystem File Search：讓 Agent 具備 glob（檔名匹配）與 grep（內容搜尋）的能力，非常適合用在程式碼庫的分析。 七、 模擬測試：LLM Tool Emulator 在開發階段，如果呼叫真實工具很貴或很慢（例如發送簡訊），你可以使用 LLMToolEmulator。它會讓另一個 LLM 來「模擬」工具的回傳結果。這讓開發者可以在不消耗實際資源的情況下，快速測試 Agent 的決策邏輯是否正確。\n八、 結語 這些內建中介軟體是 LangChain 生態系中極其強大的一部分。它們將原本需要複雜狀態管理（State Management）和錯誤處理（Error Handling）的邏輯封裝起來，讓我們能更專注於 Prompt 的調優。\n下一步，建議你挑選一個專案，試著在 create_agent 時加入 ModelCallLimitMiddleware 和 ToolRetryMiddleware。你會發現，這幾行程式碼能讓你的 AI 從「實驗室玩具」變成「生產級工具」。\n","wordCount":"194","inLanguage":"en","datePublished":"2025-10-20T00:00:00Z","dateModified":"2025-10-20T00:00:00Z","author":{"@type":"Person","name":"Aura"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://aura.codex.tw/posts/temp1.5/ep6/"},"publisher":{"@type":"Organization","name":"Aura's Space","logo":{"@type":"ImageObject","url":"https://aura.codex.tw/images/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://aura.codex.tw/ accesskey=h title="Aura's Space (Alt + H)"><img src=https://aura.codex.tw/images/favicon.ico alt aria-label=logo height=35>Aura's Space</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://aura.codex.tw/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://aura.codex.tw/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://aura.codex.tw/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://aura.codex.tw/about/ title=About><span>About</span></a></li><li><a href=https://aura.codex.tw/search/ title="🔍 (Alt + /)" accesskey=/><span>🔍</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://aura.codex.tw/>Home</a>&nbsp;»&nbsp;<a href=https://aura.codex.tw/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">【Temperature 1.5 的日常】EP6: LangChain - Built-in Middleware, 打造 AI 的全能工具箱</h1><div class=post-meta><span title='2025-10-20 00:00:00 +0000 UTC'>October 20, 2025</span>&nbsp;·&nbsp;<span>1 min</span>&nbsp;·&nbsp;<span>Aura</span></div></header><ul class=post-tags><li><a href=https://aura.codex.tw/tags/langchain/>LangChain</a></li><li><a href=https://aura.codex.tw/tags/python/>Python</a></li></ul><div class=post-content><hr><blockquote><p>本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。</p></blockquote><hr><h3 id=零-前言>零、 前言<a hidden class=anchor aria-hidden=true href=#零-前言>#</a></h3><p>接續上次我們聊到的 <strong>Human-in-the-Loop (HITL)</strong>，我們知道為了安全，必須在 AI 動手前加個「緊急煞車」。但開發一個生產等級的 Agent，光有煞車是不夠的，你可能還需要一個自動清理垃圾的清潔員、一個幫你省錢的會計師，甚至是一個能在主線掛掉時自動接手的備援司機。</p><p>在 LangChain 的世界裡，這些功能不必從零開始寫。官方提供了一整套「內建中介軟體」（Built-in Middleware），它們就像是 Agent 的各種外掛模組，插上去就能用。今天我們就來開箱這個萬能工具箱。</p><hr><h3 id=一-什麼是內建中介軟體>一、 什麼是內建中介軟體？<a hidden class=anchor aria-hidden=true href=#一-什麼是內建中介軟體>#</a></h3><p>簡單來說，中介軟體（Middleware）是介於「使用者輸入」與「模型回應」之間的邏輯層。LangChain 的內建中介軟體已經針對常見的 Agent 使用場景進行了最佳化，且大部份是 <strong>Provider-agnostic</strong>（與供應商無關），無論你底層用的是 OpenAI、Anthropic 還是本地的 Llama，通通適用。</p><p>以下是目前官方提供的核心中介軟體清單：</p><table><thead><tr><th>中介軟體</th><th>主要功能</th></tr></thead><tbody><tr><td><strong>Summarization</strong></td><td>當 Token 接近上限時，自動摘要對話歷史。</td></tr><tr><td><strong>Model/Tool Call Limit</strong></td><td>限制模型或工具的調用次數，防止成本失控。</td></tr><tr><td><strong>Model Fallback</strong></td><td>主模型失效時，自動切換到備援模型。</td></tr><tr><td><strong>PII Detection</strong></td><td>偵測並處理個人敏感資訊（如姓名、信用卡號）。</td></tr><tr><td><strong>Tool/Model Retry</strong></td><td>遇到暫時性錯誤時，自動進行指數退避重試。</td></tr><tr><td><strong>Context Editing</strong></td><td>精細管理上下文，例如清除舊的工具輸出。</td></tr><tr><td><strong>Shell / File Search</strong></td><td>提供持久的 Shell 環境或檔案搜尋能力。</td></tr></tbody></table><hr><h3 id=二-token-的管理大師summarization--context-editing>二、 Token 的管理大師：Summarization & Context Editing<a hidden class=anchor aria-hidden=true href=#二-token-的管理大師summarization--context-editing>#</a></h3><p>AI 最怕的就是「忘東忘西」或是「話太多」導致 Token 爆量。</p><h4 id=1-summarization-middleware>1. Summarization Middleware<a hidden class=anchor aria-hidden=true href=#1-summarization-middleware>#</a></h4><p>當對話變長時，這個中介軟體會自動觸發。它會保留最近的幾則訊息，並將更早之前的對話壓縮成一段摘要。</p><ul><li><strong>觸發條件（Trigger）</strong>：可以設定 Token 數、訊息數量或模型上下文的比例（Fraction）。</li><li><strong>保留內容（Keep）</strong>：指定摘要後要精確保留多少最近的對話。</li></ul><h4 id=2-context-editing-middleware>2. Context Editing Middleware<a hidden class=anchor aria-hidden=true href=#2-context-editing-middleware>#</a></h4><p>這比摘要更暴力一點，它專門處理「工具輸出」。有時候工具回傳的資料量非常大，這個中介軟體可以在 Token 達到閾值時，直接清空舊的工具訊息，只留下最核心的 <code>[cleared]</code> 標記，確保模型不會因為無關的舊資料而混淆。</p><hr><h3 id=三-成本與風險的守門員call-limits>三、 成本與風險的守門員：Call Limits<a hidden class=anchor aria-hidden=true href=#三-成本與風險的守門員call-limits>#</a></h3><p>為了防止 Agent 陷入死循環（Runaway Agents），或是開發者一覺醒來欠了幾千美金的帳單，限制機制是必備的。</p><ul><li><strong>Model Call Limit</strong>：限制單次運行（Run）或整個線程（Thread）的模型呼叫次數。</li><li><strong>Tool Call Limit</strong>：可以針對特定工具（例如搜尋、資料庫）設定限制。當次數用完時，你可以選擇讓它報錯（<code>error</code>）或是優雅地結束（<code>end</code>）。</li></ul><hr><h3 id=四-韌性與容錯fallback--retry>四、 韌性與容錯：Fallback & Retry<a hidden class=anchor aria-hidden=true href=#四-韌性與容錯fallback--retry>#</a></h3><p>在分散式系統中，網路波動或 API 下線是常態。</p><ul><li><strong>Model Fallback</strong>：你可以設定一個模型清單。如果 <code>gpt-4o</code> 壞了，自動切換到 <code>claude-3-5-sonnet</code>，確保服務不中斷。</li><li><strong>Retry Middleware</strong>：這包含對工具和對模型的重試。它支援 <strong>指數退避（Exponential Backoff）</strong>，這意味著它不會在失敗後立刻猛操 API，而是會越等越久（1 秒、2 秒、4 秒&mldr;），並加入隨機抖動（Jitter）來避免「驚群效應」。</li></ul><hr><h3 id=五-隱私守護pii-detection>五、 隱私守護：PII Detection<a hidden class=anchor aria-hidden=true href=#五-隱私守護pii-detection>#</a></h3><p>處理使用者資料時，合規性（Compliance）非常重要。<code>PIIMiddleware</code> 提供了四種處理策略：</p><ol><li><strong>Block</strong>：直接拋出異常。</li><li><strong>Redact</strong>：用 <code>[REDACTED_EMAIL]</code> 取代。</li><li><strong>Mask</strong>：部分遮蔽（如 <code>****-****-****-1234</code>）。</li><li><strong>Hash</strong>：轉換成不可逆的雜湊值。</li></ol><p>除了內建的 Email、信用卡偵測，它也支援自定義的 <strong>Regex</strong> 或 <strong>偵測函數</strong>，讓你可以針對特定國家的身分證字號進行過濾。</p><hr><h3 id=六-賦予-ai-實質能力shell--file-search>六、 賦予 AI 實質能力：Shell & File Search<a hidden class=anchor aria-hidden=true href=#六-賦予-ai-實質能力shell--file-search>#</a></h3><p>有些中介軟體不只是「過濾器」，更是「賦能器」。</p><ul><li><strong>Shell Tool Middleware</strong>：這不是單純的一次性指令，它會為 Agent 提供一個 <strong>持久（Persistent）</strong> 的 Shell 會話。這意味著 Agent 可以在第一步 <code>cd</code> 進目錄，第二步 <code>ls</code>，狀態是會保留的。為了安全，它支援 Docker 隔離與輸出脫敏。</li><li><strong>Filesystem File Search</strong>：讓 Agent 具備 <code>glob</code>（檔名匹配）與 <code>grep</code>（內容搜尋）的能力，非常適合用在程式碼庫的分析。</li></ul><hr><h3 id=七-模擬測試llm-tool-emulator>七、 模擬測試：LLM Tool Emulator<a hidden class=anchor aria-hidden=true href=#七-模擬測試llm-tool-emulator>#</a></h3><p>在開發階段，如果呼叫真實工具很貴或很慢（例如發送簡訊），你可以使用 <code>LLMToolEmulator</code>。它會讓另一個 LLM 來「模擬」工具的回傳結果。這讓開發者可以在不消耗實際資源的情況下，快速測試 Agent 的決策邏輯是否正確。</p><hr><h3 id=八-結語>八、 結語<a hidden class=anchor aria-hidden=true href=#八-結語>#</a></h3><p>這些內建中介軟體是 LangChain 生態系中極其強大的一部分。它們將原本需要複雜狀態管理（State Management）和錯誤處理（Error Handling）的邏輯封裝起來，讓我們能更專注於 Prompt 的調優。</p><p>下一步，建議你挑選一個專案，試著在 <code>create_agent</code> 時加入 <code>ModelCallLimitMiddleware</code> 和 <code>ToolRetryMiddleware</code>。你會發現，這幾行程式碼能讓你的 AI 從「實驗室玩具」變成「生產級工具」。</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022~2025 <a href=https://aura.codex.tw/>Aura's Space</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>