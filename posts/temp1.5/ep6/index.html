<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ã€Temperature 1.5 çš„æ—¥å¸¸ã€‘EP6: Ollama - è®“ LLM åœ¨å®¶è£¡ã€Œä¹–ä¹–åå¥½ã€çš„åœ¨åœ°åŒ–ç§˜è¨£ | Aura's Space</title><meta name=keywords content="LangChain,Python"><meta name=description content="

æœ¬æ–‡ç‚ºå€‹äººå­¸ç¿’ç­†è¨˜ï¼Œè¨˜éŒ„äº†å­¸ç¿’éç¨‹ä¸­çš„ä¸€äº›çŸ¥è­˜ï¼Œå¯åƒè€ƒï¼Œä½†ä¸å¯èªçœŸï¼Œå­¸ç¿’çš„éç¨‹å¯èƒ½æœ‰ç†è§£éŒ¯èª¤ï¼Œè³‡è¨Šä¸ä¸€å®šæ­£ç¢ºï¼Œç•¢ç«Ÿ Temperature éƒ½ 1.5 äº†ã€‚


é›¶ã€ å‰è¨€
æ¥çºŒä¸Šæ¬¡æˆ‘å€‘èŠåˆ°çš„ Human-in-the-Loopï¼Œæˆ‘å€‘å­¸æœƒäº†å¦‚ä½•åœ¨ AI è¡éé ­æ™‚è¸©ç…è»Šã€‚ä½†æœ‰å€‹å•é¡Œä¸€ç›´ç¸ˆç¹åœ¨å¿ƒé ­ï¼šå¦‚æœæˆ‘çš„è³‡æ–™è¶…ç´šæ•æ„Ÿï¼ˆæ¯”å¦‚å…¬å¸çš„è²¡å‹™å ±è¡¨æˆ–æ˜¯é˜¿å¬¤çš„å‚³å®¶é£Ÿè­œï¼‰ï¼Œæˆ‘çœŸçš„æ”¾å¿ƒæŠŠé€™äº›æ±è¥¿å¾€é›²ç«¯é€å—ï¼Ÿ
é€™æ™‚å€™ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹èƒ½æŠŠ AI ã€Œé—œåœ¨å®¶è£¡ã€è·‘çš„æ–¹æ¡ˆã€‚ä»Šå¤©çš„ä¸»è§’å°±æ˜¯ Ollamaã€‚å®ƒè®“ä½ åœ¨æœ¬æ©Ÿç’°å¢ƒå°±èƒ½è·‘èµ·å¼·å¤§çš„é–‹æºæ¨¡å‹ï¼Œå†æ­é… LangChain çš„æ•´åˆï¼Œç°¡ç›´æ˜¯éš±ç§æ§çš„ç¦éŸ³ã€‚

ä¸€ã€ ç‚ºä»€éº¼æ˜¯ Ollamaï¼Ÿ
Ollama æ˜¯ä¸€å€‹èƒ½è®“ä½ è¼•é¬†åœ¨å€‹äººé›»è…¦ï¼ˆWindows, macOS, Linuxï¼‰åŸ·è¡Œé–‹æºå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·ã€‚å®ƒçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ï¼š

æ‰“åŒ…ï¼ˆBundlingï¼‰ï¼šå®ƒå°‡æ¨¡å‹æ¬Šé‡ã€é…ç½®ã€è³‡æ–™å…¨éƒ¨æ‰“åŒ…æˆä¸€å€‹ç¨±ç‚º Modelfile çš„æ ¼å¼ã€‚
æœ€ä½³åŒ–ï¼ˆOptimizationï¼‰ï¼šå®ƒæœƒå¹«ä½ è™•ç†å¥½ GPU ä½¿ç”¨ç‡ç­‰åº•å±¤è¨­å®šï¼Œä½ ä¸éœ€è¦è‡ªå·±å»è·Ÿ CUDA é©…å‹•ç¨‹å¼æé¬¥ã€‚
åœ¨åœ°åŒ–ï¼ˆLocalï¼‰ï¼šæ‰€æœ‰çš„è¨ˆç®—éƒ½åœ¨ä½ çš„ç¡¬é«”ä¸Šå®Œæˆï¼Œè³‡æ–™ä¸å‡ºé–€ã€‚


äºŒã€ å¿«é€Ÿä¸Šæ‰‹ï¼šæŠŠæ¨¡å‹ã€Œæ‹–ã€é€²ä¾†
åœ¨é–‹å§‹å¯«ç¨‹å¼ç¢¼ä¹‹å‰ï¼Œæˆ‘å€‘å¾—å…ˆè®“ Ollama åœ¨é›»è…¦è£¡è·‘èµ·ä¾†ã€‚
1. å®‰è£ Ollama

macOS: ç›´æ¥ç”¨ brew install ollama æå®šã€‚
Linux/WSL: å®˜æ–¹æœ‰æä¾›å®‰è£æŒ‡ä»¤ã€‚
Windows: è‡³å®˜ç¶²ä¸‹è¼‰å®‰è£æª”ã€‚

2. ä¸‹è¼‰æ¨¡å‹
ä½ å¯ä»¥åœ¨çµ‚ç«¯æ©Ÿè¼¸å…¥æŒ‡ä»¤ä¾†ä¸‹è¼‰ä½ æƒ³è¦ç©çš„æ¨¡å‹ï¼š


1
2
3
4
5


# æŠ“å–æœ€æ–°çš„ Llama 3.1
ollama pull llama3.1

# å¦‚æœæƒ³è©¦è©¦å…·å‚™å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ gpt-oss
ollama pull gpt-oss:20b



ç­†è¨˜ï¼šæ¨¡å‹é è¨­æœƒå­˜åœ¨ ~/.ollama/models (Mac) æˆ– /usr/share/ollama/.ollama/models (Linux)ã€‚"><meta name=author content="Aura"><link rel=canonical href=https://aura.codex.tw/posts/temp1.5/ep6/><link crossorigin=anonymous href=/assets/css/stylesheet.0a190288459736d4d10e13cb6ee8068b9aa282b3f8938264b3b2d6a98bf701b7.css integrity="sha256-ChkCiEWXNtTRDhPLbugGi5qigrP4k4Jks7LWqYv3Abc=" rel="preload stylesheet" as=style><link rel=icon href=https://aura.codex.tw/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://aura.codex.tw/images/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://aura.codex.tw/images/favicon.ico><link rel=apple-touch-icon href=https://aura.codex.tw/images/favicon.ico><link rel=mask-icon href=https://aura.codex.tw/images/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://aura.codex.tw/posts/temp1.5/ep6/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://aura.codex.tw/posts/temp1.5/ep6/"><meta property="og:site_name" content="Aura's Space"><meta property="og:title" content="ã€Temperature 1.5 çš„æ—¥å¸¸ã€‘EP6: Ollama - è®“ LLM åœ¨å®¶è£¡ã€Œä¹–ä¹–åå¥½ã€çš„åœ¨åœ°åŒ–ç§˜è¨£"><meta property="og:description" content=" æœ¬æ–‡ç‚ºå€‹äººå­¸ç¿’ç­†è¨˜ï¼Œè¨˜éŒ„äº†å­¸ç¿’éç¨‹ä¸­çš„ä¸€äº›çŸ¥è­˜ï¼Œå¯åƒè€ƒï¼Œä½†ä¸å¯èªçœŸï¼Œå­¸ç¿’çš„éç¨‹å¯èƒ½æœ‰ç†è§£éŒ¯èª¤ï¼Œè³‡è¨Šä¸ä¸€å®šæ­£ç¢ºï¼Œç•¢ç«Ÿ Temperature éƒ½ 1.5 äº†ã€‚
é›¶ã€ å‰è¨€ æ¥çºŒä¸Šæ¬¡æˆ‘å€‘èŠåˆ°çš„ Human-in-the-Loopï¼Œæˆ‘å€‘å­¸æœƒäº†å¦‚ä½•åœ¨ AI è¡éé ­æ™‚è¸©ç…è»Šã€‚ä½†æœ‰å€‹å•é¡Œä¸€ç›´ç¸ˆç¹åœ¨å¿ƒé ­ï¼šå¦‚æœæˆ‘çš„è³‡æ–™è¶…ç´šæ•æ„Ÿï¼ˆæ¯”å¦‚å…¬å¸çš„è²¡å‹™å ±è¡¨æˆ–æ˜¯é˜¿å¬¤çš„å‚³å®¶é£Ÿè­œï¼‰ï¼Œæˆ‘çœŸçš„æ”¾å¿ƒæŠŠé€™äº›æ±è¥¿å¾€é›²ç«¯é€å—ï¼Ÿ
é€™æ™‚å€™ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹èƒ½æŠŠ AI ã€Œé—œåœ¨å®¶è£¡ã€è·‘çš„æ–¹æ¡ˆã€‚ä»Šå¤©çš„ä¸»è§’å°±æ˜¯ Ollamaã€‚å®ƒè®“ä½ åœ¨æœ¬æ©Ÿç’°å¢ƒå°±èƒ½è·‘èµ·å¼·å¤§çš„é–‹æºæ¨¡å‹ï¼Œå†æ­é… LangChain çš„æ•´åˆï¼Œç°¡ç›´æ˜¯éš±ç§æ§çš„ç¦éŸ³ã€‚
ä¸€ã€ ç‚ºä»€éº¼æ˜¯ Ollamaï¼Ÿ Ollama æ˜¯ä¸€å€‹èƒ½è®“ä½ è¼•é¬†åœ¨å€‹äººé›»è…¦ï¼ˆWindows, macOS, Linuxï¼‰åŸ·è¡Œé–‹æºå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·ã€‚å®ƒçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ï¼š
æ‰“åŒ…ï¼ˆBundlingï¼‰ï¼šå®ƒå°‡æ¨¡å‹æ¬Šé‡ã€é…ç½®ã€è³‡æ–™å…¨éƒ¨æ‰“åŒ…æˆä¸€å€‹ç¨±ç‚º Modelfile çš„æ ¼å¼ã€‚ æœ€ä½³åŒ–ï¼ˆOptimizationï¼‰ï¼šå®ƒæœƒå¹«ä½ è™•ç†å¥½ GPU ä½¿ç”¨ç‡ç­‰åº•å±¤è¨­å®šï¼Œä½ ä¸éœ€è¦è‡ªå·±å»è·Ÿ CUDA é©…å‹•ç¨‹å¼æé¬¥ã€‚ åœ¨åœ°åŒ–ï¼ˆLocalï¼‰ï¼šæ‰€æœ‰çš„è¨ˆç®—éƒ½åœ¨ä½ çš„ç¡¬é«”ä¸Šå®Œæˆï¼Œè³‡æ–™ä¸å‡ºé–€ã€‚ äºŒã€ å¿«é€Ÿä¸Šæ‰‹ï¼šæŠŠæ¨¡å‹ã€Œæ‹–ã€é€²ä¾† åœ¨é–‹å§‹å¯«ç¨‹å¼ç¢¼ä¹‹å‰ï¼Œæˆ‘å€‘å¾—å…ˆè®“ Ollama åœ¨é›»è…¦è£¡è·‘èµ·ä¾†ã€‚
1. å®‰è£ Ollama macOS: ç›´æ¥ç”¨ brew install ollama æå®šã€‚ Linux/WSL: å®˜æ–¹æœ‰æä¾›å®‰è£æŒ‡ä»¤ã€‚ Windows: è‡³å®˜ç¶²ä¸‹è¼‰å®‰è£æª”ã€‚ 2. ä¸‹è¼‰æ¨¡å‹ ä½ å¯ä»¥åœ¨çµ‚ç«¯æ©Ÿè¼¸å…¥æŒ‡ä»¤ä¾†ä¸‹è¼‰ä½ æƒ³è¦ç©çš„æ¨¡å‹ï¼š
1 2 3 4 5 # æŠ“å–æœ€æ–°çš„ Llama 3.1 ollama pull llama3.1 # å¦‚æœæƒ³è©¦è©¦å…·å‚™å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ gpt-oss ollama pull gpt-oss:20b ç­†è¨˜ï¼šæ¨¡å‹é è¨­æœƒå­˜åœ¨ ~/.ollama/models (Mac) æˆ– /usr/share/ollama/.ollama/models (Linux)ã€‚"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-19T00:00:00+00:00"><meta property="article:modified_time" content="2025-10-19T00:00:00+00:00"><meta property="article:tag" content="LangChain"><meta property="article:tag" content="Python"><meta name=twitter:card content="summary"><meta name=twitter:title content="ã€Temperature 1.5 çš„æ—¥å¸¸ã€‘EP6: Ollama - è®“ LLM åœ¨å®¶è£¡ã€Œä¹–ä¹–åå¥½ã€çš„åœ¨åœ°åŒ–ç§˜è¨£"><meta name=twitter:description content="

æœ¬æ–‡ç‚ºå€‹äººå­¸ç¿’ç­†è¨˜ï¼Œè¨˜éŒ„äº†å­¸ç¿’éç¨‹ä¸­çš„ä¸€äº›çŸ¥è­˜ï¼Œå¯åƒè€ƒï¼Œä½†ä¸å¯èªçœŸï¼Œå­¸ç¿’çš„éç¨‹å¯èƒ½æœ‰ç†è§£éŒ¯èª¤ï¼Œè³‡è¨Šä¸ä¸€å®šæ­£ç¢ºï¼Œç•¢ç«Ÿ Temperature éƒ½ 1.5 äº†ã€‚


é›¶ã€ å‰è¨€
æ¥çºŒä¸Šæ¬¡æˆ‘å€‘èŠåˆ°çš„ Human-in-the-Loopï¼Œæˆ‘å€‘å­¸æœƒäº†å¦‚ä½•åœ¨ AI è¡éé ­æ™‚è¸©ç…è»Šã€‚ä½†æœ‰å€‹å•é¡Œä¸€ç›´ç¸ˆç¹åœ¨å¿ƒé ­ï¼šå¦‚æœæˆ‘çš„è³‡æ–™è¶…ç´šæ•æ„Ÿï¼ˆæ¯”å¦‚å…¬å¸çš„è²¡å‹™å ±è¡¨æˆ–æ˜¯é˜¿å¬¤çš„å‚³å®¶é£Ÿè­œï¼‰ï¼Œæˆ‘çœŸçš„æ”¾å¿ƒæŠŠé€™äº›æ±è¥¿å¾€é›²ç«¯é€å—ï¼Ÿ
é€™æ™‚å€™ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹èƒ½æŠŠ AI ã€Œé—œåœ¨å®¶è£¡ã€è·‘çš„æ–¹æ¡ˆã€‚ä»Šå¤©çš„ä¸»è§’å°±æ˜¯ Ollamaã€‚å®ƒè®“ä½ åœ¨æœ¬æ©Ÿç’°å¢ƒå°±èƒ½è·‘èµ·å¼·å¤§çš„é–‹æºæ¨¡å‹ï¼Œå†æ­é… LangChain çš„æ•´åˆï¼Œç°¡ç›´æ˜¯éš±ç§æ§çš„ç¦éŸ³ã€‚

ä¸€ã€ ç‚ºä»€éº¼æ˜¯ Ollamaï¼Ÿ
Ollama æ˜¯ä¸€å€‹èƒ½è®“ä½ è¼•é¬†åœ¨å€‹äººé›»è…¦ï¼ˆWindows, macOS, Linuxï¼‰åŸ·è¡Œé–‹æºå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·ã€‚å®ƒçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ï¼š

æ‰“åŒ…ï¼ˆBundlingï¼‰ï¼šå®ƒå°‡æ¨¡å‹æ¬Šé‡ã€é…ç½®ã€è³‡æ–™å…¨éƒ¨æ‰“åŒ…æˆä¸€å€‹ç¨±ç‚º Modelfile çš„æ ¼å¼ã€‚
æœ€ä½³åŒ–ï¼ˆOptimizationï¼‰ï¼šå®ƒæœƒå¹«ä½ è™•ç†å¥½ GPU ä½¿ç”¨ç‡ç­‰åº•å±¤è¨­å®šï¼Œä½ ä¸éœ€è¦è‡ªå·±å»è·Ÿ CUDA é©…å‹•ç¨‹å¼æé¬¥ã€‚
åœ¨åœ°åŒ–ï¼ˆLocalï¼‰ï¼šæ‰€æœ‰çš„è¨ˆç®—éƒ½åœ¨ä½ çš„ç¡¬é«”ä¸Šå®Œæˆï¼Œè³‡æ–™ä¸å‡ºé–€ã€‚


äºŒã€ å¿«é€Ÿä¸Šæ‰‹ï¼šæŠŠæ¨¡å‹ã€Œæ‹–ã€é€²ä¾†
åœ¨é–‹å§‹å¯«ç¨‹å¼ç¢¼ä¹‹å‰ï¼Œæˆ‘å€‘å¾—å…ˆè®“ Ollama åœ¨é›»è…¦è£¡è·‘èµ·ä¾†ã€‚
1. å®‰è£ Ollama

macOS: ç›´æ¥ç”¨ brew install ollama æå®šã€‚
Linux/WSL: å®˜æ–¹æœ‰æä¾›å®‰è£æŒ‡ä»¤ã€‚
Windows: è‡³å®˜ç¶²ä¸‹è¼‰å®‰è£æª”ã€‚

2. ä¸‹è¼‰æ¨¡å‹
ä½ å¯ä»¥åœ¨çµ‚ç«¯æ©Ÿè¼¸å…¥æŒ‡ä»¤ä¾†ä¸‹è¼‰ä½ æƒ³è¦ç©çš„æ¨¡å‹ï¼š


1
2
3
4
5


# æŠ“å–æœ€æ–°çš„ Llama 3.1
ollama pull llama3.1

# å¦‚æœæƒ³è©¦è©¦å…·å‚™å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ gpt-oss
ollama pull gpt-oss:20b



ç­†è¨˜ï¼šæ¨¡å‹é è¨­æœƒå­˜åœ¨ ~/.ollama/models (Mac) æˆ– /usr/share/ollama/.ollama/models (Linux)ã€‚"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://aura.codex.tw/posts/"},{"@type":"ListItem","position":2,"name":"ã€Temperature 1.5 çš„æ—¥å¸¸ã€‘EP6: Ollama - è®“ LLM åœ¨å®¶è£¡ã€Œä¹–ä¹–åå¥½ã€çš„åœ¨åœ°åŒ–ç§˜è¨£","item":"https://aura.codex.tw/posts/temp1.5/ep6/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ã€Temperature 1.5 çš„æ—¥å¸¸ã€‘EP6: Ollama - è®“ LLM åœ¨å®¶è£¡ã€Œä¹–ä¹–åå¥½ã€çš„åœ¨åœ°åŒ–ç§˜è¨£","name":"ã€Temperature 1.5 çš„æ—¥å¸¸ã€‘EP6: Ollama - è®“ LLM åœ¨å®¶è£¡ã€Œä¹–ä¹–åå¥½ã€çš„åœ¨åœ°åŒ–ç§˜è¨£","description":" æœ¬æ–‡ç‚ºå€‹äººå­¸ç¿’ç­†è¨˜ï¼Œè¨˜éŒ„äº†å­¸ç¿’éç¨‹ä¸­çš„ä¸€äº›çŸ¥è­˜ï¼Œå¯åƒè€ƒï¼Œä½†ä¸å¯èªçœŸï¼Œå­¸ç¿’çš„éç¨‹å¯èƒ½æœ‰ç†è§£éŒ¯èª¤ï¼Œè³‡è¨Šä¸ä¸€å®šæ­£ç¢ºï¼Œç•¢ç«Ÿ Temperature éƒ½ 1.5 äº†ã€‚\né›¶ã€ å‰è¨€ æ¥çºŒä¸Šæ¬¡æˆ‘å€‘èŠåˆ°çš„ Human-in-the-Loopï¼Œæˆ‘å€‘å­¸æœƒäº†å¦‚ä½•åœ¨ AI è¡éé ­æ™‚è¸©ç…è»Šã€‚ä½†æœ‰å€‹å•é¡Œä¸€ç›´ç¸ˆç¹åœ¨å¿ƒé ­ï¼šå¦‚æœæˆ‘çš„è³‡æ–™è¶…ç´šæ•æ„Ÿï¼ˆæ¯”å¦‚å…¬å¸çš„è²¡å‹™å ±è¡¨æˆ–æ˜¯é˜¿å¬¤çš„å‚³å®¶é£Ÿè­œï¼‰ï¼Œæˆ‘çœŸçš„æ”¾å¿ƒæŠŠé€™äº›æ±è¥¿å¾€é›²ç«¯é€å—ï¼Ÿ\né€™æ™‚å€™ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹èƒ½æŠŠ AI ã€Œé—œåœ¨å®¶è£¡ã€è·‘çš„æ–¹æ¡ˆã€‚ä»Šå¤©çš„ä¸»è§’å°±æ˜¯ Ollamaã€‚å®ƒè®“ä½ åœ¨æœ¬æ©Ÿç’°å¢ƒå°±èƒ½è·‘èµ·å¼·å¤§çš„é–‹æºæ¨¡å‹ï¼Œå†æ­é… LangChain çš„æ•´åˆï¼Œç°¡ç›´æ˜¯éš±ç§æ§çš„ç¦éŸ³ã€‚\nä¸€ã€ ç‚ºä»€éº¼æ˜¯ Ollamaï¼Ÿ Ollama æ˜¯ä¸€å€‹èƒ½è®“ä½ è¼•é¬†åœ¨å€‹äººé›»è…¦ï¼ˆWindows, macOS, Linuxï¼‰åŸ·è¡Œé–‹æºå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·ã€‚å®ƒçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ï¼š\næ‰“åŒ…ï¼ˆBundlingï¼‰ï¼šå®ƒå°‡æ¨¡å‹æ¬Šé‡ã€é…ç½®ã€è³‡æ–™å…¨éƒ¨æ‰“åŒ…æˆä¸€å€‹ç¨±ç‚º Modelfile çš„æ ¼å¼ã€‚ æœ€ä½³åŒ–ï¼ˆOptimizationï¼‰ï¼šå®ƒæœƒå¹«ä½ è™•ç†å¥½ GPU ä½¿ç”¨ç‡ç­‰åº•å±¤è¨­å®šï¼Œä½ ä¸éœ€è¦è‡ªå·±å»è·Ÿ CUDA é©…å‹•ç¨‹å¼æé¬¥ã€‚ åœ¨åœ°åŒ–ï¼ˆLocalï¼‰ï¼šæ‰€æœ‰çš„è¨ˆç®—éƒ½åœ¨ä½ çš„ç¡¬é«”ä¸Šå®Œæˆï¼Œè³‡æ–™ä¸å‡ºé–€ã€‚ äºŒã€ å¿«é€Ÿä¸Šæ‰‹ï¼šæŠŠæ¨¡å‹ã€Œæ‹–ã€é€²ä¾† åœ¨é–‹å§‹å¯«ç¨‹å¼ç¢¼ä¹‹å‰ï¼Œæˆ‘å€‘å¾—å…ˆè®“ Ollama åœ¨é›»è…¦è£¡è·‘èµ·ä¾†ã€‚\n1. å®‰è£ Ollama macOS: ç›´æ¥ç”¨ brew install ollama æå®šã€‚ Linux/WSL: å®˜æ–¹æœ‰æä¾›å®‰è£æŒ‡ä»¤ã€‚ Windows: è‡³å®˜ç¶²ä¸‹è¼‰å®‰è£æª”ã€‚ 2. ä¸‹è¼‰æ¨¡å‹ ä½ å¯ä»¥åœ¨çµ‚ç«¯æ©Ÿè¼¸å…¥æŒ‡ä»¤ä¾†ä¸‹è¼‰ä½ æƒ³è¦ç©çš„æ¨¡å‹ï¼š\n1 2 3 4 5 # æŠ“å–æœ€æ–°çš„ Llama 3.1 ollama pull llama3.1 # å¦‚æœæƒ³è©¦è©¦å…·å‚™å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ gpt-oss ollama pull gpt-oss:20b ç­†è¨˜ï¼šæ¨¡å‹é è¨­æœƒå­˜åœ¨ ~/.ollama/models (Mac) æˆ– /usr/share/ollama/.ollama/models (Linux)ã€‚\n","keywords":["LangChain","Python"],"articleBody":" æœ¬æ–‡ç‚ºå€‹äººå­¸ç¿’ç­†è¨˜ï¼Œè¨˜éŒ„äº†å­¸ç¿’éç¨‹ä¸­çš„ä¸€äº›çŸ¥è­˜ï¼Œå¯åƒè€ƒï¼Œä½†ä¸å¯èªçœŸï¼Œå­¸ç¿’çš„éç¨‹å¯èƒ½æœ‰ç†è§£éŒ¯èª¤ï¼Œè³‡è¨Šä¸ä¸€å®šæ­£ç¢ºï¼Œç•¢ç«Ÿ Temperature éƒ½ 1.5 äº†ã€‚\né›¶ã€ å‰è¨€ æ¥çºŒä¸Šæ¬¡æˆ‘å€‘èŠåˆ°çš„ Human-in-the-Loopï¼Œæˆ‘å€‘å­¸æœƒäº†å¦‚ä½•åœ¨ AI è¡éé ­æ™‚è¸©ç…è»Šã€‚ä½†æœ‰å€‹å•é¡Œä¸€ç›´ç¸ˆç¹åœ¨å¿ƒé ­ï¼šå¦‚æœæˆ‘çš„è³‡æ–™è¶…ç´šæ•æ„Ÿï¼ˆæ¯”å¦‚å…¬å¸çš„è²¡å‹™å ±è¡¨æˆ–æ˜¯é˜¿å¬¤çš„å‚³å®¶é£Ÿè­œï¼‰ï¼Œæˆ‘çœŸçš„æ”¾å¿ƒæŠŠé€™äº›æ±è¥¿å¾€é›²ç«¯é€å—ï¼Ÿ\né€™æ™‚å€™ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹èƒ½æŠŠ AI ã€Œé—œåœ¨å®¶è£¡ã€è·‘çš„æ–¹æ¡ˆã€‚ä»Šå¤©çš„ä¸»è§’å°±æ˜¯ Ollamaã€‚å®ƒè®“ä½ åœ¨æœ¬æ©Ÿç’°å¢ƒå°±èƒ½è·‘èµ·å¼·å¤§çš„é–‹æºæ¨¡å‹ï¼Œå†æ­é… LangChain çš„æ•´åˆï¼Œç°¡ç›´æ˜¯éš±ç§æ§çš„ç¦éŸ³ã€‚\nä¸€ã€ ç‚ºä»€éº¼æ˜¯ Ollamaï¼Ÿ Ollama æ˜¯ä¸€å€‹èƒ½è®“ä½ è¼•é¬†åœ¨å€‹äººé›»è…¦ï¼ˆWindows, macOS, Linuxï¼‰åŸ·è¡Œé–‹æºå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·ã€‚å®ƒçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ï¼š\næ‰“åŒ…ï¼ˆBundlingï¼‰ï¼šå®ƒå°‡æ¨¡å‹æ¬Šé‡ã€é…ç½®ã€è³‡æ–™å…¨éƒ¨æ‰“åŒ…æˆä¸€å€‹ç¨±ç‚º Modelfile çš„æ ¼å¼ã€‚ æœ€ä½³åŒ–ï¼ˆOptimizationï¼‰ï¼šå®ƒæœƒå¹«ä½ è™•ç†å¥½ GPU ä½¿ç”¨ç‡ç­‰åº•å±¤è¨­å®šï¼Œä½ ä¸éœ€è¦è‡ªå·±å»è·Ÿ CUDA é©…å‹•ç¨‹å¼æé¬¥ã€‚ åœ¨åœ°åŒ–ï¼ˆLocalï¼‰ï¼šæ‰€æœ‰çš„è¨ˆç®—éƒ½åœ¨ä½ çš„ç¡¬é«”ä¸Šå®Œæˆï¼Œè³‡æ–™ä¸å‡ºé–€ã€‚ äºŒã€ å¿«é€Ÿä¸Šæ‰‹ï¼šæŠŠæ¨¡å‹ã€Œæ‹–ã€é€²ä¾† åœ¨é–‹å§‹å¯«ç¨‹å¼ç¢¼ä¹‹å‰ï¼Œæˆ‘å€‘å¾—å…ˆè®“ Ollama åœ¨é›»è…¦è£¡è·‘èµ·ä¾†ã€‚\n1. å®‰è£ Ollama macOS: ç›´æ¥ç”¨ brew install ollama æå®šã€‚ Linux/WSL: å®˜æ–¹æœ‰æä¾›å®‰è£æŒ‡ä»¤ã€‚ Windows: è‡³å®˜ç¶²ä¸‹è¼‰å®‰è£æª”ã€‚ 2. ä¸‹è¼‰æ¨¡å‹ ä½ å¯ä»¥åœ¨çµ‚ç«¯æ©Ÿè¼¸å…¥æŒ‡ä»¤ä¾†ä¸‹è¼‰ä½ æƒ³è¦ç©çš„æ¨¡å‹ï¼š\n1 2 3 4 5 # æŠ“å–æœ€æ–°çš„ Llama 3.1 ollama pull llama3.1 # å¦‚æœæƒ³è©¦è©¦å…·å‚™å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ gpt-oss ollama pull gpt-oss:20b ç­†è¨˜ï¼šæ¨¡å‹é è¨­æœƒå­˜åœ¨ ~/.ollama/models (Mac) æˆ– /usr/share/ollama/.ollama/models (Linux)ã€‚\nä¸‰ã€ LangChain èˆ‡ Ollama çš„å¼·å¼·è¯æ‰‹ è¦è®“ LangChain æ§åˆ¶ Ollamaï¼Œæˆ‘å€‘éœ€è¦å®‰è£å°ˆç”¨çš„æ•´åˆå¥—ä»¶ï¼š\n1 pip install -qU langchain-ollama å¯¦ä½œï¼šåŸºæœ¬èª¿ç”¨ï¼ˆInvocationï¼‰ æˆ‘å€‘ä¾†å¯«ä¸€å€‹ç°¡å–®çš„ç¿»è­¯åŠ©æ‰‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from langchain_ollama import ChatOllama # å»ºç«‹æ¨¡å‹ç‰©ä»¶ llm = ChatOllama( model=\"llama3.1\", temperature=0, ) # æº–å‚™è¨Šæ¯ messages = [ (\"system\", \"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¿»è­¯å®˜ï¼Œè² è²¬æŠŠè‹±æ–‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚\"), (\"human\", \"I love programming with LangChain.\"), ] # å‘¼å«æ¨¡å‹ ai_msg = llm.invoke(messages) print(ai_msg.content) å››ã€ é€²éšåŠŸèƒ½ï¼šAI ä¸åªæ˜¯æœƒèŠå¤© Ollama é€é ChatOllama é¡åˆ¥ï¼Œå…¶å¯¦æ”¯æ´äº†å¾ˆå¤šç¾ä»£æ¨¡å‹æ‰æœ‰çš„ç‰¹ç•°åŠŸèƒ½ï¼š\n1. å·¥å…·èª¿ç”¨ï¼ˆTool Callingï¼‰ æœ‰äº›æ¨¡å‹ï¼ˆå¦‚ gpt-ossï¼‰ç¶“éå¾®èª¿ï¼Œå¯ä»¥ç²¾æº–åœ°æ±ºå®šä½•æ™‚è©²ã€Œå»æŸ¥è³‡æ–™ã€æˆ–ã€Œå‘¼å«å‡½æ•¸ã€ã€‚\nåŠŸèƒ½ æ”¯æ´æƒ…æ³ å‚™è¨» JSON Mode âœ… å¼·åˆ¶è¼¸å‡º JSON æ ¼å¼ Token æµå¼è¼¸å‡º âœ… å³å•å³ç­”ï¼Œä¸ç”¨ä¹¾ç­‰ åŸç”ŸéåŒæ­¥ âœ… æå‡ç¨‹å¼åŸ·è¡Œæ•ˆç‡ å¤šæ¨¡æ…‹è¼¸å…¥ âœ… æ”¯æ´åœ–ç‰‡ç†è§£ï¼ˆå¦‚ bakllavaï¼‰ 2. å¤šæ¨¡æ…‹ç¯„ä¾‹ï¼ˆçœ‹åœ–èªªæ•…äº‹ï¼‰ å¦‚æœä½ ä½¿ç”¨çš„æ¨¡å‹æ”¯æ´è¦–è¦ºï¼ˆä¾‹å¦‚ bakllava æˆ– gemma3ï¼‰ï¼Œä½ å¯ä»¥æŠŠåœ–ç‰‡è½‰æˆ Base64 ç·¨ç¢¼å¡é€²å»ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ç¤ºæ„ä»£ç¢¼ï¼šå‚³é€åœ–ç‰‡çµ¦æ¨¡å‹ from langchain_ollama import ChatOllama from langchain.messages import HumanMessage llm = ChatOllama(model=\"bakllava\") # æ§‹å»ºåŒ…å«åœ–ç‰‡èˆ‡æ–‡å­—çš„è¨Šæ¯ content = [ {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{image_b64}\"}, {\"type\": \"text\", \"text\": \"é€™å¼µåœ–è¡¨ä¸­çš„æˆé•·ç‡æ˜¯å¤šå°‘ï¼Ÿ\"} ] response = llm.invoke([HumanMessage(content=content)]) print(response.content) äº”ã€ æ¨ç†æ¨¡å‹èˆ‡è‡ªå®šç¾©è§’è‰² æœ€è¿‘å¾ˆç´…çš„ã€Œæ¨ç†æ¨¡å‹ã€ï¼ˆReasoning Modelsï¼‰ï¼Œä¾‹å¦‚ IBM çš„ Granite 3.2ï¼Œæ”¯æ´ä¸€ç¨®ç‰¹åˆ¥çš„æ¨¡å¼ä¾†å±•ç¤ºå®ƒçš„ã€Œå¿ƒè·¯æ­·ç¨‹ã€ã€‚\nåœ¨ ChatOllama ä¸­ï¼Œæˆ‘å€‘å¯ä»¥é€ééæ¨™æº–çš„ ChatMessage ä¾†å•Ÿå‹•é€™å€‹æ©Ÿåˆ¶ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 from langchain_core.messages import ChatMessage from langchain_ollama import ChatOllama llm = ChatOllama(model=\"granite3.2:8b\") messages = [ # è¨­å®šæ§åˆ¶è§’è‰²ç‚º 'thinking' ChatMessage(role=\"control\", content=\"thinking\"), HumanMessage(\"ç‚ºä»€éº¼ 3^3 ç­‰æ–¼ 27ï¼Ÿ\"), ] response = llm.invoke(messages) print(response.content) é€™æ™‚å€™ï¼Œä½ æœƒç™¼ç¾æ¨¡å‹è¼¸å‡ºçš„å…§å®¹æœƒåŒ…å« Thought Processï¼Œè®“ä½ çŸ¥é“å®ƒæ˜¯æ€éº¼ä¸€æ­¥æ­¥ç®—å‡ºä¾†çš„ï¼Œè€Œä¸åªæ˜¯çµ¦ä¸€å€‹å†·å†°å†°çš„ç­”æ¡ˆã€‚\nå…­ã€ æ³¨æ„äº‹é …èˆ‡è¸©å‘ç­†è¨˜ ç‰ˆæœ¬æ›´æ–°ï¼šOllama é€²åŒ–éå¸¸å¿«ï¼Œå»ºè­°æ™‚ä¸æ™‚è·‘ä¸€ä¸‹ pip install -U ollama ç¢ºä¿é©…å‹•å±¤æ˜¯æœ€æ–°çš„ã€‚ æ¨¡å‹æ¨™ç±¤ï¼šä¸‹è¼‰æ™‚è‹¥ä¸æŒ‡å®š tagï¼Œé è¨­é€šå¸¸æ˜¯è©²æ¨¡å‹æœ€å°ã€æœ€ç²¾ç°¡çš„ç‰ˆæœ¬ã€‚å¦‚æœä½ çš„è¨˜æ†¶é«”å¤ å¤§ï¼Œå¯ä»¥è©¦è‘—æŠ“ 70b ä¹‹é¡çš„å·¨ç¸ã€‚ æ•ˆèƒ½ç“¶é ¸ï¼šåœ¨åœ°åŒ–è·‘æ¨¡å‹ï¼Œé›»è…¦é¢¨æ‰‡ç‹‚è½‰æ˜¯æ­£å¸¸çš„ï¼Œé‚£æ˜¯ã€ŒAI çš„å¿ƒè·³è²ã€ã€‚ ä¸ƒã€ çµèª Ollama è®“ã€Œç§æœ‰åŒ– AIã€é€™ä»¶äº‹å¾å¯¦é©—å®¤èµ°å‘äº†æ¯å€‹äººçš„æ¡Œé¢ã€‚ç•¶æˆ‘å€‘æŠŠ ChatOllama æ”¾å…¥ LangChain çš„å·¥ä½œæµä¸­ï¼Œæˆ‘å€‘å°±æ“æœ‰äº†ä¸€å€‹æ—¢å®‰å…¨ã€åˆå¼·å¤§ï¼Œä¸”å®Œå…¨ç”±è‡ªå·±ä¸»å®°çš„æ™ºæ…§å¤§è…¦ã€‚\nä¸‹æ¬¡å¦‚æœä½ åœ¨æ·±å¤œå¯«æ‰£ï¼Œä¸æƒ³è®“é›²ç«¯æœå‹™çŸ¥é“ä½ åœ¨å¹¹å˜›ï¼Œå°±æŠŠ Ollama å«èµ·ä¾†é™ªä½ å§ï¼\n","wordCount":"312","inLanguage":"en","datePublished":"2025-10-19T00:00:00Z","dateModified":"2025-10-19T00:00:00Z","author":{"@type":"Person","name":"Aura"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://aura.codex.tw/posts/temp1.5/ep6/"},"publisher":{"@type":"Organization","name":"Aura's Space","logo":{"@type":"ImageObject","url":"https://aura.codex.tw/images/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://aura.codex.tw/ accesskey=h title="Aura's Space (Alt + H)"><img src=https://aura.codex.tw/images/favicon.ico alt aria-label=logo height=35>Aura's Space</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://aura.codex.tw/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://aura.codex.tw/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://aura.codex.tw/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://aura.codex.tw/about/ title=About><span>About</span></a></li><li><a href=https://aura.codex.tw/search/ title="ğŸ” (Alt + /)" accesskey=/><span>ğŸ”</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://aura.codex.tw/>Home</a>&nbsp;Â»&nbsp;<a href=https://aura.codex.tw/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">ã€Temperature 1.5 çš„æ—¥å¸¸ã€‘EP6: Ollama - è®“ LLM åœ¨å®¶è£¡ã€Œä¹–ä¹–åå¥½ã€çš„åœ¨åœ°åŒ–ç§˜è¨£</h1><div class=post-meta><span title='2025-10-19 00:00:00 +0000 UTC'>October 19, 2025</span>&nbsp;Â·&nbsp;<span>2 min</span>&nbsp;Â·&nbsp;<span>Aura</span></div></header><ul class=post-tags><li><a href=https://aura.codex.tw/tags/langchain/>LangChain</a></li><li><a href=https://aura.codex.tw/tags/python/>Python</a></li></ul><div class=post-content><hr><blockquote><p>æœ¬æ–‡ç‚ºå€‹äººå­¸ç¿’ç­†è¨˜ï¼Œè¨˜éŒ„äº†å­¸ç¿’éç¨‹ä¸­çš„ä¸€äº›çŸ¥è­˜ï¼Œå¯åƒè€ƒï¼Œä½†ä¸å¯èªçœŸï¼Œå­¸ç¿’çš„éç¨‹å¯èƒ½æœ‰ç†è§£éŒ¯èª¤ï¼Œè³‡è¨Šä¸ä¸€å®šæ­£ç¢ºï¼Œç•¢ç«Ÿ Temperature éƒ½ 1.5 äº†ã€‚</p></blockquote><hr><h3 id=é›¶-å‰è¨€>é›¶ã€ å‰è¨€<a hidden class=anchor aria-hidden=true href=#é›¶-å‰è¨€>#</a></h3><p>æ¥çºŒä¸Šæ¬¡æˆ‘å€‘èŠåˆ°çš„ <strong>Human-in-the-Loop</strong>ï¼Œæˆ‘å€‘å­¸æœƒäº†å¦‚ä½•åœ¨ AI è¡éé ­æ™‚è¸©ç…è»Šã€‚ä½†æœ‰å€‹å•é¡Œä¸€ç›´ç¸ˆç¹åœ¨å¿ƒé ­ï¼šå¦‚æœæˆ‘çš„è³‡æ–™è¶…ç´šæ•æ„Ÿï¼ˆæ¯”å¦‚å…¬å¸çš„è²¡å‹™å ±è¡¨æˆ–æ˜¯é˜¿å¬¤çš„å‚³å®¶é£Ÿè­œï¼‰ï¼Œæˆ‘çœŸçš„æ”¾å¿ƒæŠŠé€™äº›æ±è¥¿å¾€é›²ç«¯é€å—ï¼Ÿ</p><p>é€™æ™‚å€™ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹èƒ½æŠŠ AI ã€Œé—œåœ¨å®¶è£¡ã€è·‘çš„æ–¹æ¡ˆã€‚ä»Šå¤©çš„ä¸»è§’å°±æ˜¯ <strong>Ollama</strong>ã€‚å®ƒè®“ä½ åœ¨æœ¬æ©Ÿç’°å¢ƒå°±èƒ½è·‘èµ·å¼·å¤§çš„é–‹æºæ¨¡å‹ï¼Œå†æ­é… <strong>LangChain</strong> çš„æ•´åˆï¼Œç°¡ç›´æ˜¯éš±ç§æ§çš„ç¦éŸ³ã€‚</p><hr><h3 id=ä¸€-ç‚ºä»€éº¼æ˜¯-ollama>ä¸€ã€ ç‚ºä»€éº¼æ˜¯ Ollamaï¼Ÿ<a hidden class=anchor aria-hidden=true href=#ä¸€-ç‚ºä»€éº¼æ˜¯-ollama>#</a></h3><p><strong>Ollama</strong> æ˜¯ä¸€å€‹èƒ½è®“ä½ è¼•é¬†åœ¨å€‹äººé›»è…¦ï¼ˆWindows, macOS, Linuxï¼‰åŸ·è¡Œé–‹æºå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·ã€‚å®ƒçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ï¼š</p><ol><li><strong>æ‰“åŒ…ï¼ˆBundlingï¼‰</strong>ï¼šå®ƒå°‡æ¨¡å‹æ¬Šé‡ã€é…ç½®ã€è³‡æ–™å…¨éƒ¨æ‰“åŒ…æˆä¸€å€‹ç¨±ç‚º <code>Modelfile</code> çš„æ ¼å¼ã€‚</li><li><strong>æœ€ä½³åŒ–ï¼ˆOptimizationï¼‰</strong>ï¼šå®ƒæœƒå¹«ä½ è™•ç†å¥½ GPU ä½¿ç”¨ç‡ç­‰åº•å±¤è¨­å®šï¼Œä½ ä¸éœ€è¦è‡ªå·±å»è·Ÿ CUDA é©…å‹•ç¨‹å¼æé¬¥ã€‚</li><li><strong>åœ¨åœ°åŒ–ï¼ˆLocalï¼‰</strong>ï¼šæ‰€æœ‰çš„è¨ˆç®—éƒ½åœ¨ä½ çš„ç¡¬é«”ä¸Šå®Œæˆï¼Œè³‡æ–™ä¸å‡ºé–€ã€‚</li></ol><hr><h3 id=äºŒ-å¿«é€Ÿä¸Šæ‰‹æŠŠæ¨¡å‹æ‹–é€²ä¾†>äºŒã€ å¿«é€Ÿä¸Šæ‰‹ï¼šæŠŠæ¨¡å‹ã€Œæ‹–ã€é€²ä¾†<a hidden class=anchor aria-hidden=true href=#äºŒ-å¿«é€Ÿä¸Šæ‰‹æŠŠæ¨¡å‹æ‹–é€²ä¾†>#</a></h3><p>åœ¨é–‹å§‹å¯«ç¨‹å¼ç¢¼ä¹‹å‰ï¼Œæˆ‘å€‘å¾—å…ˆè®“ Ollama åœ¨é›»è…¦è£¡è·‘èµ·ä¾†ã€‚</p><h4 id=1-å®‰è£-ollama>1. å®‰è£ Ollama<a hidden class=anchor aria-hidden=true href=#1-å®‰è£-ollama>#</a></h4><ul><li><strong>macOS</strong>: ç›´æ¥ç”¨ <code>brew install ollama</code> æå®šã€‚</li><li><strong>Linux/WSL</strong>: å®˜æ–¹æœ‰æä¾›å®‰è£æŒ‡ä»¤ã€‚</li><li><strong>Windows</strong>: è‡³å®˜ç¶²ä¸‹è¼‰å®‰è£æª”ã€‚</li></ul><h4 id=2-ä¸‹è¼‰æ¨¡å‹>2. ä¸‹è¼‰æ¨¡å‹<a hidden class=anchor aria-hidden=true href=#2-ä¸‹è¼‰æ¨¡å‹>#</a></h4><p>ä½ å¯ä»¥åœ¨çµ‚ç«¯æ©Ÿè¼¸å…¥æŒ‡ä»¤ä¾†ä¸‹è¼‰ä½ æƒ³è¦ç©çš„æ¨¡å‹ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># æŠ“å–æœ€æ–°çš„ Llama 3.1</span>
</span></span><span class=line><span class=cl>ollama pull llama3.1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># å¦‚æœæƒ³è©¦è©¦å…·å‚™å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ gpt-oss</span>
</span></span><span class=line><span class=cl>ollama pull gpt-oss:20b
</span></span></code></pre></td></tr></table></div></div><blockquote><p><strong>ç­†è¨˜</strong>ï¼šæ¨¡å‹é è¨­æœƒå­˜åœ¨ <code>~/.ollama/models</code> (Mac) æˆ– <code>/usr/share/ollama/.ollama/models</code> (Linux)ã€‚</p></blockquote><hr><h3 id=ä¸‰-langchain-èˆ‡-ollama-çš„å¼·å¼·è¯æ‰‹>ä¸‰ã€ LangChain èˆ‡ Ollama çš„å¼·å¼·è¯æ‰‹<a hidden class=anchor aria-hidden=true href=#ä¸‰-langchain-èˆ‡-ollama-çš„å¼·å¼·è¯æ‰‹>#</a></h3><p>è¦è®“ LangChain æ§åˆ¶ Ollamaï¼Œæˆ‘å€‘éœ€è¦å®‰è£å°ˆç”¨çš„æ•´åˆå¥—ä»¶ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install -qU langchain-ollama
</span></span></code></pre></td></tr></table></div></div><h4 id=å¯¦ä½œåŸºæœ¬èª¿ç”¨invocation>å¯¦ä½œï¼šåŸºæœ¬èª¿ç”¨ï¼ˆInvocationï¼‰<a hidden class=anchor aria-hidden=true href=#å¯¦ä½œåŸºæœ¬èª¿ç”¨invocation>#</a></h4><p>æˆ‘å€‘ä¾†å¯«ä¸€å€‹ç°¡å–®çš„ç¿»è­¯åŠ©æ‰‹ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_ollama</span> <span class=kn>import</span> <span class=n>ChatOllama</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># å»ºç«‹æ¨¡å‹ç‰©ä»¶</span>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>ChatOllama</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;llama3.1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># æº–å‚™è¨Šæ¯</span>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¿»è­¯å®˜ï¼Œè² è²¬æŠŠè‹±æ–‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=s2>&#34;human&#34;</span><span class=p>,</span> <span class=s2>&#34;I love programming with LangChain.&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># å‘¼å«æ¨¡å‹</span>
</span></span><span class=line><span class=cl><span class=n>ai_msg</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>ai_msg</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><hr><h3 id=å››-é€²éšåŠŸèƒ½ai-ä¸åªæ˜¯æœƒèŠå¤©>å››ã€ é€²éšåŠŸèƒ½ï¼šAI ä¸åªæ˜¯æœƒèŠå¤©<a hidden class=anchor aria-hidden=true href=#å››-é€²éšåŠŸèƒ½ai-ä¸åªæ˜¯æœƒèŠå¤©>#</a></h3><p>Ollama é€é <code>ChatOllama</code> é¡åˆ¥ï¼Œå…¶å¯¦æ”¯æ´äº†å¾ˆå¤šç¾ä»£æ¨¡å‹æ‰æœ‰çš„ç‰¹ç•°åŠŸèƒ½ï¼š</p><h4 id=1-å·¥å…·èª¿ç”¨tool-calling>1. å·¥å…·èª¿ç”¨ï¼ˆTool Callingï¼‰<a hidden class=anchor aria-hidden=true href=#1-å·¥å…·èª¿ç”¨tool-calling>#</a></h4><p>æœ‰äº›æ¨¡å‹ï¼ˆå¦‚ <code>gpt-oss</code>ï¼‰ç¶“éå¾®èª¿ï¼Œå¯ä»¥ç²¾æº–åœ°æ±ºå®šä½•æ™‚è©²ã€Œå»æŸ¥è³‡æ–™ã€æˆ–ã€Œå‘¼å«å‡½æ•¸ã€ã€‚</p><table><thead><tr><th>åŠŸèƒ½</th><th>æ”¯æ´æƒ…æ³</th><th>å‚™è¨»</th></tr></thead><tbody><tr><td><strong>JSON Mode</strong></td><td>âœ…</td><td>å¼·åˆ¶è¼¸å‡º JSON æ ¼å¼</td></tr><tr><td><strong>Token æµå¼è¼¸å‡º</strong></td><td>âœ…</td><td>å³å•å³ç­”ï¼Œä¸ç”¨ä¹¾ç­‰</td></tr><tr><td><strong>åŸç”ŸéåŒæ­¥</strong></td><td>âœ…</td><td>æå‡ç¨‹å¼åŸ·è¡Œæ•ˆç‡</td></tr><tr><td><strong>å¤šæ¨¡æ…‹è¼¸å…¥</strong></td><td>âœ…</td><td>æ”¯æ´åœ–ç‰‡ç†è§£ï¼ˆå¦‚ <code>bakllava</code>ï¼‰</td></tr></tbody></table><h4 id=2-å¤šæ¨¡æ…‹ç¯„ä¾‹çœ‹åœ–èªªæ•…äº‹>2. å¤šæ¨¡æ…‹ç¯„ä¾‹ï¼ˆçœ‹åœ–èªªæ•…äº‹ï¼‰<a hidden class=anchor aria-hidden=true href=#2-å¤šæ¨¡æ…‹ç¯„ä¾‹çœ‹åœ–èªªæ•…äº‹>#</a></h4><p>å¦‚æœä½ ä½¿ç”¨çš„æ¨¡å‹æ”¯æ´è¦–è¦ºï¼ˆä¾‹å¦‚ <code>bakllava</code> æˆ– <code>gemma3</code>ï¼‰ï¼Œä½ å¯ä»¥æŠŠåœ–ç‰‡è½‰æˆ Base64 ç·¨ç¢¼å¡é€²å»ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ç¤ºæ„ä»£ç¢¼ï¼šå‚³é€åœ–ç‰‡çµ¦æ¨¡å‹</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_ollama</span> <span class=kn>import</span> <span class=n>ChatOllama</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.messages</span> <span class=kn>import</span> <span class=n>HumanMessage</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>ChatOllama</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;bakllava&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># æ§‹å»ºåŒ…å«åœ–ç‰‡èˆ‡æ–‡å­—çš„è¨Šæ¯</span>
</span></span><span class=line><span class=cl><span class=n>content</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span> <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>image_b64</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;é€™å¼µåœ–è¡¨ä¸­çš„æˆé•·ç‡æ˜¯å¤šå°‘ï¼Ÿ&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>invoke</span><span class=p>([</span><span class=n>HumanMessage</span><span class=p>(</span><span class=n>content</span><span class=o>=</span><span class=n>content</span><span class=p>)])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><hr><h3 id=äº”-æ¨ç†æ¨¡å‹èˆ‡è‡ªå®šç¾©è§’è‰²>äº”ã€ æ¨ç†æ¨¡å‹èˆ‡è‡ªå®šç¾©è§’è‰²<a hidden class=anchor aria-hidden=true href=#äº”-æ¨ç†æ¨¡å‹èˆ‡è‡ªå®šç¾©è§’è‰²>#</a></h3><p>æœ€è¿‘å¾ˆç´…çš„ã€Œæ¨ç†æ¨¡å‹ã€ï¼ˆReasoning Modelsï¼‰ï¼Œä¾‹å¦‚ IBM çš„ <code>Granite 3.2</code>ï¼Œæ”¯æ´ä¸€ç¨®ç‰¹åˆ¥çš„æ¨¡å¼ä¾†å±•ç¤ºå®ƒçš„ã€Œå¿ƒè·¯æ­·ç¨‹ã€ã€‚</p><p>åœ¨ <code>ChatOllama</code> ä¸­ï¼Œæˆ‘å€‘å¯ä»¥é€ééæ¨™æº–çš„ <code>ChatMessage</code> ä¾†å•Ÿå‹•é€™å€‹æ©Ÿåˆ¶ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_core.messages</span> <span class=kn>import</span> <span class=n>ChatMessage</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_ollama</span> <span class=kn>import</span> <span class=n>ChatOllama</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>ChatOllama</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;granite3.2:8b&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=c1># è¨­å®šæ§åˆ¶è§’è‰²ç‚º &#39;thinking&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>ChatMessage</span><span class=p>(</span><span class=n>role</span><span class=o>=</span><span class=s2>&#34;control&#34;</span><span class=p>,</span> <span class=n>content</span><span class=o>=</span><span class=s2>&#34;thinking&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>HumanMessage</span><span class=p>(</span><span class=s2>&#34;ç‚ºä»€éº¼ 3^3 ç­‰æ–¼ 27ï¼Ÿ&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>é€™æ™‚å€™ï¼Œä½ æœƒç™¼ç¾æ¨¡å‹è¼¸å‡ºçš„å…§å®¹æœƒåŒ…å« <strong>Thought Process</strong>ï¼Œè®“ä½ çŸ¥é“å®ƒæ˜¯æ€éº¼ä¸€æ­¥æ­¥ç®—å‡ºä¾†çš„ï¼Œè€Œä¸åªæ˜¯çµ¦ä¸€å€‹å†·å†°å†°çš„ç­”æ¡ˆã€‚</p><hr><h3 id=å…­-æ³¨æ„äº‹é …èˆ‡è¸©å‘ç­†è¨˜>å…­ã€ æ³¨æ„äº‹é …èˆ‡è¸©å‘ç­†è¨˜<a hidden class=anchor aria-hidden=true href=#å…­-æ³¨æ„äº‹é …èˆ‡è¸©å‘ç­†è¨˜>#</a></h3><ol><li><strong>ç‰ˆæœ¬æ›´æ–°</strong>ï¼šOllama é€²åŒ–éå¸¸å¿«ï¼Œå»ºè­°æ™‚ä¸æ™‚è·‘ä¸€ä¸‹ <code>pip install -U ollama</code> ç¢ºä¿é©…å‹•å±¤æ˜¯æœ€æ–°çš„ã€‚</li><li><strong>æ¨¡å‹æ¨™ç±¤</strong>ï¼šä¸‹è¼‰æ™‚è‹¥ä¸æŒ‡å®š tagï¼Œé è¨­é€šå¸¸æ˜¯è©²æ¨¡å‹æœ€å°ã€æœ€ç²¾ç°¡çš„ç‰ˆæœ¬ã€‚å¦‚æœä½ çš„è¨˜æ†¶é«”å¤ å¤§ï¼Œå¯ä»¥è©¦è‘—æŠ“ <code>70b</code> ä¹‹é¡çš„å·¨ç¸ã€‚</li><li><strong>æ•ˆèƒ½ç“¶é ¸</strong>ï¼šåœ¨åœ°åŒ–è·‘æ¨¡å‹ï¼Œé›»è…¦é¢¨æ‰‡ç‹‚è½‰æ˜¯æ­£å¸¸çš„ï¼Œé‚£æ˜¯ã€ŒAI çš„å¿ƒè·³è²ã€ã€‚</li></ol><hr><h3 id=ä¸ƒ-çµèª>ä¸ƒã€ çµèª<a hidden class=anchor aria-hidden=true href=#ä¸ƒ-çµèª>#</a></h3><p><strong>Ollama</strong> è®“ã€Œç§æœ‰åŒ– AIã€é€™ä»¶äº‹å¾å¯¦é©—å®¤èµ°å‘äº†æ¯å€‹äººçš„æ¡Œé¢ã€‚ç•¶æˆ‘å€‘æŠŠ <strong>ChatOllama</strong> æ”¾å…¥ LangChain çš„å·¥ä½œæµä¸­ï¼Œæˆ‘å€‘å°±æ“æœ‰äº†ä¸€å€‹æ—¢å®‰å…¨ã€åˆå¼·å¤§ï¼Œä¸”å®Œå…¨ç”±è‡ªå·±ä¸»å®°çš„æ™ºæ…§å¤§è…¦ã€‚</p><p>ä¸‹æ¬¡å¦‚æœä½ åœ¨æ·±å¤œå¯«æ‰£ï¼Œä¸æƒ³è®“é›²ç«¯æœå‹™çŸ¥é“ä½ åœ¨å¹¹å˜›ï¼Œå°±æŠŠ Ollama å«èµ·ä¾†é™ªä½ å§ï¼</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022~2025 <a href=https://aura.codex.tw/>Aura's Space</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>