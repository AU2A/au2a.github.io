<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。   零、 前言接續上次我們聊到的 Human-in-the-Loop，我們學會了如何在 AI 衝過頭時踩煞車。但有個問題一直縈繞在心頭：如果我的資料超級敏感（比如公司的財務報表或是阿嬤的傳家食譜），我真的放心把這些東西往雲端送嗎？ 這時候">
<meta property="og:type" content="article">
<meta property="og:title" content="【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣">
<meta property="og:url" content="http://example.com/2025/10/19/Temp1.5/EP6/index.html">
<meta property="og:site_name" content="Aura&#39;s Space">
<meta property="og:description" content="本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。   零、 前言接續上次我們聊到的 Human-in-the-Loop，我們學會了如何在 AI 衝過頭時踩煞車。但有個問題一直縈繞在心頭：如果我的資料超級敏感（比如公司的財務報表或是阿嬤的傳家食譜），我真的放心把這些東西往雲端送嗎？ 這時候">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-10-18T16:00:00.000Z">
<meta property="article:modified_time" content="2025-12-22T14:19:00.761Z">
<meta property="article:author" content="Aura">
<meta property="article:tag" content="LangChain">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
      
    
    <!-- title -->
    <title>【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2025/10/26/APCS/APCS-2021-11/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2025/10/18/Temp1.5/EP5/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2025/10/19/Temp1.5/EP6/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2025/10/19/Temp1.5/EP6/&text=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2025/10/19/Temp1.5/EP6/&is_video=false&description=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣&body=Check out this article: http://example.com/2025/10/19/Temp1.5/EP6/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2025/10/19/Temp1.5/EP6/&name=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2025/10/19/Temp1.5/EP6/&t=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%B6%E3%80%81-%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">零、 前言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81-%E7%82%BA%E4%BB%80%E9%BA%BC%E6%98%AF-Ollama%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">一、 為什麼是 Ollama？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%EF%BC%9A%E6%8A%8A%E6%A8%A1%E5%9E%8B%E3%80%8C%E6%8B%96%E3%80%8D%E9%80%B2%E4%BE%86"><span class="toc-number">3.</span> <span class="toc-text">二、 快速上手：把模型「拖」進來</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%AE%89%E8%A3%9D-Ollama"><span class="toc-number">3.1.</span> <span class="toc-text">1. 安裝 Ollama</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%B8%8B%E8%BC%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">2. 下載模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81-LangChain-%E8%88%87-Ollama-%E7%9A%84%E5%BC%B7%E5%BC%B7%E8%81%AF%E6%89%8B"><span class="toc-number">4.</span> <span class="toc-text">三、 LangChain 與 Ollama 的強強聯手</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%A6%E4%BD%9C%EF%BC%9A%E5%9F%BA%E6%9C%AC%E8%AA%BF%E7%94%A8%EF%BC%88Invocation%EF%BC%89"><span class="toc-number">4.1.</span> <span class="toc-text">實作：基本調用（Invocation）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81-%E9%80%B2%E9%9A%8E%E5%8A%9F%E8%83%BD%EF%BC%9AAI-%E4%B8%8D%E5%8F%AA%E6%98%AF%E6%9C%83%E8%81%8A%E5%A4%A9"><span class="toc-number">5.</span> <span class="toc-text">四、 進階功能：AI 不只是會聊天</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%B7%A5%E5%85%B7%E8%AA%BF%E7%94%A8%EF%BC%88Tool-Calling%EF%BC%89"><span class="toc-number">5.1.</span> <span class="toc-text">1. 工具調用（Tool Calling）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%A4%9A%E6%A8%A1%E6%85%8B%E7%AF%84%E4%BE%8B%EF%BC%88%E7%9C%8B%E5%9C%96%E8%AA%AA%E6%95%85%E4%BA%8B%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">2. 多模態範例（看圖說故事）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%94%E3%80%81-%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E8%88%87%E8%87%AA%E5%AE%9A%E7%BE%A9%E8%A7%92%E8%89%B2"><span class="toc-number">6.</span> <span class="toc-text">五、 推理模型與自定義角色</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E3%80%81-%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A0%85%E8%88%87%E8%B8%A9%E5%9D%91%E7%AD%86%E8%A8%98"><span class="toc-number">7.</span> <span class="toc-text">六、 注意事項與踩坑筆記</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%83%E3%80%81-%E7%B5%90%E8%AA%9E"><span class="toc-number">8.</span> <span class="toc-text">七、 結語</span></a></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣
    </h1>



      <div class="meta">
        <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <span class="p-name" itemprop="name">
            Aura
                    
          </span>
        </span>
        
    <div class="postdate">
      
        <time datetime="2025-10-18T16:00:00.000Z" class="dt-published" itemprop="datePublished">2025-10-19</time>
        
      
    </div>


          
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/Temperature-1-5/">Temperature 1.5</a>
    </div>


            
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/LangChain/" rel="tag">LangChain</a>, <a class="p-category" href="/tags/Python/" rel="tag">Python</a>
    </div>


      </div>
  </header>
  

    <div class="content e-content" itemprop="articleBody">
      <hr>
<blockquote>
<p>本文為個人學習筆記，記錄了學習過程中的一些知識，可參考，但不可認真，學習的過程可能有理解錯誤，資訊不一定正確，畢竟 Temperature 都 1.5 了。</p>
</blockquote>
<hr>
<h3 id="零、-前言"><a href="#零、-前言" class="headerlink" title="零、 前言"></a>零、 前言</h3><p>接續上次我們聊到的 <strong>Human-in-the-Loop</strong>，我們學會了如何在 AI 衝過頭時踩煞車。但有個問題一直縈繞在心頭：如果我的資料超級敏感（比如公司的財務報表或是阿嬤的傳家食譜），我真的放心把這些東西往雲端送嗎？</p>
<p>這時候，我們需要一個能把 AI 「關在家裡」跑的方案。今天的主角就是 <strong>Ollama</strong>。它讓你在本機環境就能跑起強大的開源模型，再搭配 <strong>LangChain</strong> 的整合，簡直是隱私控的福音。</p>
<hr>
<h3 id="一、-為什麼是-Ollama？"><a href="#一、-為什麼是-Ollama？" class="headerlink" title="一、 為什麼是 Ollama？"></a>一、 為什麼是 Ollama？</h3><p><strong>Ollama</strong> 是一個能讓你輕鬆在個人電腦（Windows, macOS, Linux）執行開源大型語言模型（LLM）的工具。它的核心概念是：</p>
<ol>
<li><strong>打包（Bundling）</strong>：它將模型權重、配置、資料全部打包成一個稱為 <code>Modelfile</code> 的格式。</li>
<li><strong>最佳化（Optimization）</strong>：它會幫你處理好 GPU 使用率等底層設定，你不需要自己去跟 CUDA 驅動程式搏鬥。</li>
<li><strong>在地化（Local）</strong>：所有的計算都在你的硬體上完成，資料不出門。</li>
</ol>
<hr>
<h3 id="二、-快速上手：把模型「拖」進來"><a href="#二、-快速上手：把模型「拖」進來" class="headerlink" title="二、 快速上手：把模型「拖」進來"></a>二、 快速上手：把模型「拖」進來</h3><p>在開始寫程式碼之前，我們得先讓 Ollama 在電腦裡跑起來。</p>
<h4 id="1-安裝-Ollama"><a href="#1-安裝-Ollama" class="headerlink" title="1. 安裝 Ollama"></a>1. 安裝 Ollama</h4><ul>
<li><strong>macOS</strong>: 直接用 <code>brew install ollama</code> 搞定。</li>
<li><strong>Linux&#x2F;WSL</strong>: 官方有提供安裝指令。</li>
<li><strong>Windows</strong>: 至官網下載安裝檔。</li>
</ul>
<h4 id="2-下載模型"><a href="#2-下載模型" class="headerlink" title="2. 下載模型"></a>2. 下載模型</h4><p>你可以在終端機輸入指令來下載你想要玩的模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 抓取最新的 Llama 3.1</span></span><br><span class="line">ollama pull llama3.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果想試試具備工具調用能力的 gpt-oss</span></span><br><span class="line">ollama pull gpt-oss:20b</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>筆記</strong>：模型預設會存在 <code>~/.ollama/models</code> (Mac) 或 <code>/usr/share/ollama/.ollama/models</code> (Linux)。</p>
</blockquote>
<hr>
<h3 id="三、-LangChain-與-Ollama-的強強聯手"><a href="#三、-LangChain-與-Ollama-的強強聯手" class="headerlink" title="三、 LangChain 與 Ollama 的強強聯手"></a>三、 LangChain 與 Ollama 的強強聯手</h3><p>要讓 LangChain 控制 Ollama，我們需要安裝專用的整合套件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install -qU langchain-ollama</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="實作：基本調用（Invocation）"><a href="#實作：基本調用（Invocation）" class="headerlink" title="實作：基本調用（Invocation）"></a>實作：基本調用（Invocation）</h4><p>我們來寫一個簡單的翻譯助手。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型物件</span></span><br><span class="line">llm = ChatOllama(</span><br><span class="line">    model=<span class="string">&quot;llama3.1&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 準備訊息</span></span><br><span class="line">messages = [</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一個專業的翻譯官，負責把英文翻譯成繁體中文。&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;I love programming with LangChain.&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 呼叫模型</span></span><br><span class="line">ai_msg = llm.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(ai_msg.content)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="四、-進階功能：AI-不只是會聊天"><a href="#四、-進階功能：AI-不只是會聊天" class="headerlink" title="四、 進階功能：AI 不只是會聊天"></a>四、 進階功能：AI 不只是會聊天</h3><p>Ollama 透過 <code>ChatOllama</code> 類別，其實支援了很多現代模型才有的特異功能：</p>
<h4 id="1-工具調用（Tool-Calling）"><a href="#1-工具調用（Tool-Calling）" class="headerlink" title="1. 工具調用（Tool Calling）"></a>1. 工具調用（Tool Calling）</h4><p>有些模型（如 <code>gpt-oss</code>）經過微調，可以精準地決定何時該「去查資料」或「呼叫函數」。</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>支援情況</th>
<th>備註</th>
</tr>
</thead>
<tbody><tr>
<td><strong>JSON Mode</strong></td>
<td>✅</td>
<td>強制輸出 JSON 格式</td>
</tr>
<tr>
<td><strong>Token 流式輸出</strong></td>
<td>✅</td>
<td>即問即答，不用乾等</td>
</tr>
<tr>
<td><strong>原生非同步</strong></td>
<td>✅</td>
<td>提升程式執行效率</td>
</tr>
<tr>
<td><strong>多模態輸入</strong></td>
<td>✅</td>
<td>支援圖片理解（如 <code>bakllava</code>）</td>
</tr>
</tbody></table>
<h4 id="2-多模態範例（看圖說故事）"><a href="#2-多模態範例（看圖說故事）" class="headerlink" title="2. 多模態範例（看圖說故事）"></a>2. 多模態範例（看圖說故事）</h4><p>如果你使用的模型支援視覺（例如 <code>bakllava</code> 或 <code>gemma3</code>），你可以把圖片轉成 Base64 編碼塞進去。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示意代碼：傳送圖片給模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line"></span><br><span class="line">llm = ChatOllama(model=<span class="string">&quot;bakllava&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 構建包含圖片與文字的訊息</span></span><br><span class="line">content = [</span><br><span class="line">    &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;image_url&quot;</span>, <span class="string">&quot;image_url&quot;</span>: <span class="string">f&quot;data:image/jpeg;base64,<span class="subst">&#123;image_b64&#125;</span>&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>, <span class="string">&quot;text&quot;</span>: <span class="string">&quot;這張圖表中的成長率是多少？&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">response = llm.invoke([HumanMessage(content=content)])</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="五、-推理模型與自定義角色"><a href="#五、-推理模型與自定義角色" class="headerlink" title="五、 推理模型與自定義角色"></a>五、 推理模型與自定義角色</h3><p>最近很紅的「推理模型」（Reasoning Models），例如 IBM 的 <code>Granite 3.2</code>，支援一種特別的模式來展示它的「心路歷程」。</p>
<p>在 <code>ChatOllama</code> 中，我們可以透過非標準的 <code>ChatMessage</code> 來啟動這個機制：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> ChatMessage</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"></span><br><span class="line">llm = ChatOllama(model=<span class="string">&quot;granite3.2:8b&quot;</span>)</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    <span class="comment"># 設定控制角色為 &#x27;thinking&#x27;</span></span><br><span class="line">    ChatMessage(role=<span class="string">&quot;control&quot;</span>, content=<span class="string">&quot;thinking&quot;</span>),</span><br><span class="line">    HumanMessage(<span class="string">&quot;為什麼 3^3 等於 27？&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">response = llm.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>這時候，你會發現模型輸出的內容會包含 <strong>Thought Process</strong>，讓你知道它是怎麼一步步算出來的，而不只是給一個冷冰冰的答案。</p>
<hr>
<h3 id="六、-注意事項與踩坑筆記"><a href="#六、-注意事項與踩坑筆記" class="headerlink" title="六、 注意事項與踩坑筆記"></a>六、 注意事項與踩坑筆記</h3><ol>
<li><strong>版本更新</strong>：Ollama 進化非常快，建議時不時跑一下 <code>pip install -U ollama</code> 確保驅動層是最新的。</li>
<li><strong>模型標籤</strong>：下載時若不指定 tag，預設通常是該模型最小、最精簡的版本。如果你的記憶體夠大，可以試著抓 <code>70b</code> 之類的巨獸。</li>
<li><strong>效能瓶頸</strong>：在地化跑模型，電腦風扇狂轉是正常的，那是「AI 的心跳聲」。</li>
</ol>
<hr>
<h3 id="七、-結語"><a href="#七、-結語" class="headerlink" title="七、 結語"></a>七、 結語</h3><p><strong>Ollama</strong> 讓「私有化 AI」這件事從實驗室走向了每個人的桌面。當我們把 <strong>ChatOllama</strong> 放入 LangChain 的工作流中，我們就擁有了一個既安全、又強大，且完全由自己主宰的智慧大腦。</p>
<p>下次如果你在深夜寫扣，不想讓雲端服務知道你在幹嘛，就把 Ollama 叫起來陪你吧！</p>

    </div>
</article>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%B6%E3%80%81-%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">零、 前言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81-%E7%82%BA%E4%BB%80%E9%BA%BC%E6%98%AF-Ollama%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">一、 為什麼是 Ollama？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%EF%BC%9A%E6%8A%8A%E6%A8%A1%E5%9E%8B%E3%80%8C%E6%8B%96%E3%80%8D%E9%80%B2%E4%BE%86"><span class="toc-number">3.</span> <span class="toc-text">二、 快速上手：把模型「拖」進來</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%AE%89%E8%A3%9D-Ollama"><span class="toc-number">3.1.</span> <span class="toc-text">1. 安裝 Ollama</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%B8%8B%E8%BC%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">2. 下載模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81-LangChain-%E8%88%87-Ollama-%E7%9A%84%E5%BC%B7%E5%BC%B7%E8%81%AF%E6%89%8B"><span class="toc-number">4.</span> <span class="toc-text">三、 LangChain 與 Ollama 的強強聯手</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%A6%E4%BD%9C%EF%BC%9A%E5%9F%BA%E6%9C%AC%E8%AA%BF%E7%94%A8%EF%BC%88Invocation%EF%BC%89"><span class="toc-number">4.1.</span> <span class="toc-text">實作：基本調用（Invocation）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81-%E9%80%B2%E9%9A%8E%E5%8A%9F%E8%83%BD%EF%BC%9AAI-%E4%B8%8D%E5%8F%AA%E6%98%AF%E6%9C%83%E8%81%8A%E5%A4%A9"><span class="toc-number">5.</span> <span class="toc-text">四、 進階功能：AI 不只是會聊天</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%B7%A5%E5%85%B7%E8%AA%BF%E7%94%A8%EF%BC%88Tool-Calling%EF%BC%89"><span class="toc-number">5.1.</span> <span class="toc-text">1. 工具調用（Tool Calling）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%A4%9A%E6%A8%A1%E6%85%8B%E7%AF%84%E4%BE%8B%EF%BC%88%E7%9C%8B%E5%9C%96%E8%AA%AA%E6%95%85%E4%BA%8B%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">2. 多模態範例（看圖說故事）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%94%E3%80%81-%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E8%88%87%E8%87%AA%E5%AE%9A%E7%BE%A9%E8%A7%92%E8%89%B2"><span class="toc-number">6.</span> <span class="toc-text">五、 推理模型與自定義角色</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E3%80%81-%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A0%85%E8%88%87%E8%B8%A9%E5%9D%91%E7%AD%86%E8%A8%98"><span class="toc-number">7.</span> <span class="toc-text">六、 注意事項與踩坑筆記</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%83%E3%80%81-%E7%B5%90%E8%AA%9E"><span class="toc-number">8.</span> <span class="toc-text">七、 結語</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2025/10/19/Temp1.5/EP6/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2025/10/19/Temp1.5/EP6/&text=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2025/10/19/Temp1.5/EP6/&is_video=false&description=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣&body=Check out this article: http://example.com/2025/10/19/Temp1.5/EP6/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2025/10/19/Temp1.5/EP6/&title=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2025/10/19/Temp1.5/EP6/&name=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2025/10/19/Temp1.5/EP6/&t=【Temperature 1.5 的日常】EP6: Ollama - 讓 LLM 在家裡「乖乖坐好」的在地化秘訣"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2025
    Aura
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
