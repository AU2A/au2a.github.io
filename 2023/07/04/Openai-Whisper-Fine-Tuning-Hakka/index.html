<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="連結Github 重點專案結構1234567891011whisper_hakka ┗┳━ audio  ┃   ┣━ test  ┃   ┃   ┗━ test語料存放區  ┃   ┣━ train  ┃   ┃   ┗━ train語料存放區  ┃   ┗━ metadata.csv 檔案路徑與文本內容  ┣━ model  ┃   ┗━ 模型存放區  ┣━ fine_tune.ipynb j">
<meta property="og:type" content="article">
<meta property="og:title" content="Openai Whisper Fine-Tuning - Hakka">
<meta property="og:url" content="http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/index.html">
<meta property="og:site_name" content="Aura&#39;s Space">
<meta property="og:description" content="連結Github 重點專案結構1234567891011whisper_hakka ┗┳━ audio  ┃   ┣━ test  ┃   ┃   ┗━ test語料存放區  ┃   ┣━ train  ┃   ┃   ┗━ train語料存放區  ┃   ┗━ metadata.csv 檔案路徑與文本內容  ┣━ model  ┃   ┗━ 模型存放區  ┣━ fine_tune.ipynb j">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-07-04T01:42:49.000Z">
<meta property="article:modified_time" content="2024-04-13T02:07:21.000Z">
<meta property="article:author" content="Aura">
<meta property="article:tag" content="Aura&#39;s Space">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
      
    
    <!-- title -->
    <title>Openai Whisper Fine-Tuning - Hakka</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2023/08/14/LeetCode/LeetCode-2023-08/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2023/07/03/LeetCode/LeetCode-2023-07/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&text=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&is_video=false&description=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Openai Whisper Fine-Tuning - Hakka&body=Check out this article: http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&name=Openai Whisper Fine-Tuning - Hakka&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&t=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%A3%E7%B5%90"><span class="toc-number">1.</span> <span class="toc-text">連結</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E9%BB%9E%E5%B0%88%E6%A1%88%E7%B5%90%E6%A7%8B"><span class="toc-number">2.</span> <span class="toc-text">重點專案結構</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%89%E8%A3%9D-cuda"><span class="toc-number">3.</span> <span class="toc-text">安裝 cuda</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cuda"><span class="toc-number">3.0.0.1.</span> <span class="toc-text">cuda</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#driver"><span class="toc-number">3.0.0.2.</span> <span class="toc-text">driver</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Huggingface-%E9%87%91%E9%91%B0%E7%94%B3%E8%AB%8B"><span class="toc-number">4.</span> <span class="toc-text">Huggingface 金鑰申請</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A8%8B%E5%BC%8F%E7%A2%BC%E8%AA%AA%E6%98%8E"><span class="toc-number">5.</span> <span class="toc-text">程式碼說明</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%E5%90%8D%E7%A8%B1"><span class="toc-number">5.0.0.1.</span> <span class="toc-text">建立模型名稱</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%99%BB%E5%85%A5-hugging-face"><span class="toc-number">5.0.0.2.</span> <span class="toc-text">登入 hugging face</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BC%89%E5%85%A5%E9%9F%B3%E6%AA%94%E8%B3%87%E6%96%99"><span class="toc-number">5.0.0.3.</span> <span class="toc-text">載入音檔資料</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BC%89%E5%85%A5-Openai-%E5%BB%BA%E7%AB%8B%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.0.0.4.</span> <span class="toc-text">載入 Openai 建立好的模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AA%9E%E6%96%99%E8%BD%89%E6%8F%9B%E5%8F%96%E6%A8%A3%E7%8E%87"><span class="toc-number">5.0.0.5.</span> <span class="toc-text">語料轉換取樣率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#data-collator"><span class="toc-number">5.0.0.6.</span> <span class="toc-text">data_collator</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#compute-metrics"><span class="toc-number">5.0.0.7.</span> <span class="toc-text">compute_metrics</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#model"><span class="toc-number">5.0.0.8.</span> <span class="toc-text">model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#training-args"><span class="toc-number">5.0.0.9.</span> <span class="toc-text">training_args</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#trainer"><span class="toc-number">5.0.0.10.</span> <span class="toc-text">trainer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%96%8B%E5%A7%8B%E8%A8%93%E7%B7%B4"><span class="toc-number">5.0.0.11.</span> <span class="toc-text">開始訓練</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%9E%E6%9C%AC%E5%9C%B0%E4%B8%8A%E5%82%B3%E6%A8%A1%E5%9E%8B%E5%88%B0-HuggingFace"><span class="toc-number">5.0.0.12.</span> <span class="toc-text">從本地上傳模型到 HuggingFace</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%9E-HuggingFace-%E4%B8%8B%E8%BC%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.0.0.13.</span> <span class="toc-text">從 HuggingFace 下載模型</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#reference"><span class="toc-number">6.</span> <span class="toc-text">reference</span></a></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        Openai Whisper Fine-Tuning - Hakka
    </h1>



      <div class="meta">
        <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <span class="p-name" itemprop="name">
            Aura
                    
          </span>
        </span>
        
    <div class="postdate">
      
        <time datetime="2023-07-04T01:42:49.000Z" class="dt-published" itemprop="datePublished">2023-07-04</time>
        
      
    </div>


          
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/HakkaASR/">HakkaASR</a>
    </div>


            

      </div>
  </header>
  

    <div class="content e-content" itemprop="articleBody">
      <h1 id="連結"><a href="#連結" class="headerlink" title="連結"></a>連結</h1><p><a target="_blank" rel="noopener" href="https://github.com/AU2A/whisper_finetuning">Github</a></p>
<h1 id="重點專案結構"><a href="#重點專案結構" class="headerlink" title="重點專案結構"></a>重點專案結構</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">whisper_hakka</span><br><span class="line"> ┗┳━ audio</span><br><span class="line">  ┃   ┣━ test</span><br><span class="line">  ┃   ┃   ┗━ test語料存放區</span><br><span class="line">  ┃   ┣━ train</span><br><span class="line">  ┃   ┃   ┗━ train語料存放區</span><br><span class="line">  ┃   ┗━ metadata.csv 檔案路徑與文本內容</span><br><span class="line">  ┣━ model</span><br><span class="line">  ┃   ┗━ 模型存放區</span><br><span class="line">  ┣━ fine_tune.ipynb jupyter訓練腳本</span><br><span class="line">  ┗━ huggingface_token huggingfacer金鑰</span><br></pre></td></tr></table></figure>

<h1 id="安裝-cuda"><a href="#安裝-cuda" class="headerlink" title="安裝 cuda"></a>安裝 cuda</h1><h4 id="cuda"><a href="#cuda" class="headerlink" title="cuda"></a>cuda</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run</span><br><span class="line">sudo sh cuda_11.4.0_470.42.01_linux.run</span><br></pre></td></tr></table></figure>

<p>如果要獨立裝 driver，就把 driver 取消</p>
<h4 id="driver"><a href="#driver" class="headerlink" title="driver"></a>driver</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nvidia-driver-470</span><br></pre></td></tr></table></figure>

<h1 id="Huggingface-金鑰申請"><a href="#Huggingface-金鑰申請" class="headerlink" title="Huggingface 金鑰申請"></a>Huggingface 金鑰申請</h1><p>請到<a target="_blank" rel="noopener" href="https://huggingface.co/">huggingface 官網</a><br>右上的選項 → <code>Settings</code> → <code>Access Tokens</code><br>點選<code>New token</code>，<code>Name</code>自訂，<code>Role</code>選<code>write</code><br><code>Generate a token</code>後，將產生的<code>token</code>複製貼上到專案的<code>huggingface_token</code></p>
<h1 id="程式碼說明"><a href="#程式碼說明" class="headerlink" title="程式碼說明"></a>程式碼說明</h1><h4 id="建立模型名稱"><a href="#建立模型名稱" class="headerlink" title="建立模型名稱"></a>建立模型名稱</h4><p>請輸入檔案名稱</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_name=<span class="string">&#x27;model name&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="登入-hugging-face"><a href="#登入-hugging-face" class="headerlink" title="登入 hugging face"></a>登入 hugging face</h4><p>將訓練完成的模型上傳到存放在 huggingface，可以減少本地端空間占用。<br><code>Token</code>請自行去 huggingface 申請</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub.hf_api <span class="keyword">import</span> HfFolder</span><br><span class="line">token=<span class="built_in">open</span>(<span class="string">&#x27;huggingface_token&#x27;</span>,<span class="string">&#x27;r&#x27;</span>).readlines()[<span class="number">0</span>].split(<span class="string">&#x27;\n&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">HfFolder.save_token(token)</span><br></pre></td></tr></table></figure>

<h4 id="載入音檔資料"><a href="#載入音檔資料" class="headerlink" title="載入音檔資料"></a>載入音檔資料</h4><p>會從<code>data_dir</code>底下拉語料進行使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line">common_voice = load_dataset(<span class="string">&quot;./&quot;</span>, data_dir=<span class="string">&quot;audio&quot;</span>,use_auth_token=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 可以使用以下程式碼查看dataset結構</span></span><br><span class="line"><span class="built_in">print</span>(common_voice)</span><br></pre></td></tr></table></figure>

<h4 id="載入-Openai-建立好的模型"><a href="#載入-Openai-建立好的模型" class="headerlink" title="載入 Openai 建立好的模型"></a>載入 Openai 建立好的模型</h4><p>使用 openai 提供的基礎模型，模型大小或語言，請自行更換</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor</span><br><span class="line">feature_extractor = WhisperFeatureExtractor.from_pretrained(<span class="string">&quot;openai/whisper-base&quot;</span>)</span><br><span class="line">tokenizer = WhisperTokenizer.from_pretrained(<span class="string">&quot;openai/whisper-base&quot;</span>, language=<span class="string">&quot;zh&quot;</span>, task=<span class="string">&quot;transcribe&quot;</span>)</span><br><span class="line">processor = WhisperProcessor.from_pretrained(<span class="string">&quot;openai/whisper-base&quot;</span>, language=<span class="string">&quot;zh&quot;</span>, task=<span class="string">&quot;transcribe&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="語料轉換取樣率"><a href="#語料轉換取樣率" class="headerlink" title="語料轉換取樣率"></a>語料轉換取樣率</h4><p>音檔取樣率轉換成 16000HkHz</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Audio</span><br><span class="line">common_voice = common_voice.cast_column(<span class="string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="number">16000</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_dataset</span>(<span class="params">batch</span>):</span><br><span class="line">    audio = batch[<span class="string">&quot;audio&quot;</span>]</span><br><span class="line">    batch[<span class="string">&quot;input_features&quot;</span>] = feature_extractor(audio[<span class="string">&quot;array&quot;</span>], sampling_rate=audio[<span class="string">&quot;sampling_rate&quot;</span>]).input_features[<span class="number">0</span>]</span><br><span class="line">    batch[<span class="string">&quot;labels&quot;</span>] = tokenizer(batch[<span class="string">&quot;sentence&quot;</span>]).input_ids</span><br><span class="line">    <span class="keyword">return</span> batch</span><br><span class="line"></span><br><span class="line">common_voice = common_voice.<span class="built_in">map</span>(prepare_dataset, remove_columns=common_voice.column_names[<span class="string">&quot;train&quot;</span>], num_proc=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="data-collator"><a href="#data-collator" class="headerlink" title="data_collator"></a>data_collator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Any</span>, <span class="type">Dict</span>, <span class="type">List</span>, <span class="type">Union</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataCollatorSpeechSeq2SeqWithPadding</span>:</span><br><span class="line">    processor: <span class="type">Any</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, features: <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Union</span>[<span class="type">List</span>[<span class="built_in">int</span>], torch.Tensor]]]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, torch.Tensor]:</span><br><span class="line">        <span class="comment"># split inputs and labels since they have to be of different lengths and need different padding methods</span></span><br><span class="line">        <span class="comment"># first treat the audio inputs by simply returning torch tensors</span></span><br><span class="line">        input_features = [&#123;<span class="string">&quot;input_features&quot;</span>: feature[<span class="string">&quot;input_features&quot;</span>]&#125; <span class="keyword">for</span> feature <span class="keyword">in</span> features]</span><br><span class="line">        batch = self.processor.feature_extractor.pad(input_features, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get the tokenized label sequences</span></span><br><span class="line">        label_features = [&#123;<span class="string">&quot;input_ids&quot;</span>: feature[<span class="string">&quot;labels&quot;</span>]&#125; <span class="keyword">for</span> feature <span class="keyword">in</span> features]</span><br><span class="line">        <span class="comment"># pad the labels to max length</span></span><br><span class="line">        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># replace padding with -100 to ignore loss correctly</span></span><br><span class="line">        labels = labels_batch[<span class="string">&quot;input_ids&quot;</span>].masked_fill(labels_batch.attention_mask.ne(<span class="number">1</span>), -<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if bos token is appended in previous tokenization step,</span></span><br><span class="line">        <span class="comment"># cut bos token here as it&#x27;s append later anyways</span></span><br><span class="line">        <span class="keyword">if</span> (labels[:, <span class="number">0</span>] == self.processor.tokenizer.bos_token_id).<span class="built_in">all</span>().cpu().item():</span><br><span class="line">            labels = labels[:, <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        batch[<span class="string">&quot;labels&quot;</span>] = labels</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> batch</span><br><span class="line"></span><br><span class="line">data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)</span><br></pre></td></tr></table></figure>

<h4 id="compute-metrics"><a href="#compute-metrics" class="headerlink" title="compute_metrics"></a>compute_metrics</h4><p>計算 CER(或 WER)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">metric = evaluate.load(<span class="string">&quot;cer&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">pred</span>):</span><br><span class="line">    pred_ids = pred.predictions</span><br><span class="line">    label_ids = pred.label_ids</span><br><span class="line"></span><br><span class="line">    <span class="comment"># replace -100 with the pad_token_id</span></span><br><span class="line">    label_ids[label_ids == -<span class="number">100</span>] = tokenizer.pad_token_id</span><br><span class="line"></span><br><span class="line">    <span class="comment"># we do not want to group tokens when computing the metrics</span></span><br><span class="line">    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    cer = <span class="number">100</span> * metric.compute(predictions=pred_str, references=label_str)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;cer&quot;</span>: cer&#125;</span><br></pre></td></tr></table></figure>

<h4 id="model"><a href="#model" class="headerlink" title="model"></a>model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> WhisperForConditionalGeneration</span><br><span class="line"></span><br><span class="line">model = WhisperForConditionalGeneration.from_pretrained(<span class="string">&quot;openai/whisper-base&quot;</span>)</span><br><span class="line">model.config.forced_decoder_ids = <span class="literal">None</span></span><br><span class="line">model.config.suppress_tokens = []</span><br></pre></td></tr></table></figure>

<h4 id="training-args"><a href="#training-args" class="headerlink" title="training_args"></a>training_args</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Seq2SeqTrainingArguments</span><br><span class="line"></span><br><span class="line">training_args = Seq2SeqTrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./model_name&quot;</span>, <span class="comment"># 模型名稱，你需要更改</span></span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>, <span class="comment"># 批次大小，你可能會需要調整</span></span><br><span class="line">    gradient_accumulation_steps=<span class="number">1</span>,</span><br><span class="line">    learning_rate=<span class="number">1e-5</span>, <span class="comment"># 學習率，你可能會需要調整</span></span><br><span class="line">    warmup_steps=<span class="number">500</span>,</span><br><span class="line">    max_steps=<span class="number">4000</span>, <span class="comment"># 訓練次數，你可能會需要調整</span></span><br><span class="line">    gradient_checkpointing=<span class="literal">True</span>,</span><br><span class="line">    fp16=<span class="literal">True</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">    per_device_eval_batch_size=<span class="number">8</span>,</span><br><span class="line">    predict_with_generate=<span class="literal">True</span>,</span><br><span class="line">    generation_max_length=<span class="number">225</span>,</span><br><span class="line">    save_steps=<span class="number">1000</span>,</span><br><span class="line">    eval_steps=<span class="number">1000</span>,</span><br><span class="line">    logging_steps=<span class="number">25</span>,</span><br><span class="line">    report_to=[<span class="string">&quot;tensorboard&quot;</span>],</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">    metric_for_best_model=<span class="string">&quot;cer&quot;</span>,</span><br><span class="line">    greater_is_better=<span class="literal">False</span>,</span><br><span class="line">    push_to_hub=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="trainer"><a href="#trainer" class="headerlink" title="trainer"></a>trainer</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Seq2SeqTrainer</span><br><span class="line"></span><br><span class="line">trainer = Seq2SeqTrainer(</span><br><span class="line">    args=training_args,</span><br><span class="line">    model=model,</span><br><span class="line">    train_dataset=common_voice[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=common_voice[<span class="string">&quot;test&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">    tokenizer=processor.feature_extractor,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">processor.save_pretrained(training_args.output_dir)</span><br></pre></td></tr></table></figure>

<h4 id="開始訓練"><a href="#開始訓練" class="headerlink" title="開始訓練"></a>開始訓練</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<h4 id="從本地上傳模型到-HuggingFace"><a href="#從本地上傳模型到-HuggingFace" class="headerlink" title="從本地上傳模型到 HuggingFace"></a>從本地上傳模型到 HuggingFace</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kwargs = &#123;</span><br><span class="line">    <span class="string">&quot;dataset_tags&quot;</span>: <span class="string">&quot;-&quot;</span>,</span><br><span class="line">    <span class="string">&quot;dataset&quot;</span>: <span class="string">&quot;some hakka audio&quot;</span>,  <span class="comment"># 輸入資料及名稱</span></span><br><span class="line">    <span class="string">&quot;dataset_args&quot;</span>: <span class="string">&quot;config: zh, split: test&quot;</span>,</span><br><span class="line">    <span class="string">&quot;language&quot;</span>: <span class="string">&quot;zh&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model_name&quot;</span>: <span class="string">&quot;a name&quot;</span>,  <span class="comment"># 輸入模型名稱</span></span><br><span class="line">    <span class="string">&quot;finetuned_from&quot;</span>: <span class="string">&quot;openai/whisper-base&quot;</span>, <span class="comment"># 基礎模型</span></span><br><span class="line">    <span class="string">&quot;tasks&quot;</span>: <span class="string">&quot;automatic-speech-recognition&quot;</span>,</span><br><span class="line">    <span class="string">&quot;tags&quot;</span>: <span class="string">&quot;whisper&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trainer.push_to_hub(**kwargs)</span><br></pre></td></tr></table></figure>

<h4 id="從-HuggingFace-下載模型"><a href="#從-HuggingFace-下載模型" class="headerlink" title="從 HuggingFace 下載模型"></a>從 HuggingFace 下載模型</h4><p>你需要更改要下載 model 的位置與存放位置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiple_datasets.hub_default_utils <span class="keyword">import</span> convert_hf_whisper</span><br><span class="line"></span><br><span class="line">model_name_or_path = <span class="string">&#x27;model_name_on_hugging_face&#x27;</span></span><br><span class="line">whisper_checkpoint_path = <span class="string">&#x27;save_model_path&#x27;</span></span><br><span class="line"></span><br><span class="line">convert_hf_whisper(model_name_or_path, whisper_checkpoint_path)</span><br></pre></td></tr></table></figure>

<h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb#scrollTo=810ced54-7187-4a06-b2fe-ba6dcca94dc3">https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb#scrollTo=810ced54-7187-4a06-b2fe-ba6dcca94dc3</a><br><a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1RkboArXsuXIEDTE5OHfJe-0Gn7v3gXI1?usp=sharing#scrollTo=-hxbi4vVPpoy">https://colab.research.google.com/drive/1RkboArXsuXIEDTE5OHfJe-0Gn7v3gXI1?usp=sharing#scrollTo=-hxbi4vVPpoy</a><br><a target="_blank" rel="noopener" href="https://wandb.ai/parambharat/whisper_finetuning/reports/Fine-tuning-Whisper-ASR-models---VmlldzozMTEzNDE5">https://wandb.ai/parambharat/whisper_finetuning/reports/Fine-tuning-Whisper-ASR-models---VmlldzozMTEzNDE5</a><br><a target="_blank" rel="noopener" href="https://huggingface.co/jlondonobo/whisper-medium-pt">https://huggingface.co/jlondonobo/whisper-medium-pt</a><br><a target="_blank" rel="noopener" href="https://github.com/bayartsogt-ya/whisper-multiple-hf-datasets">https://github.com/bayartsogt-ya/whisper-multiple-hf-datasets</a><br><a target="_blank" rel="noopener" href="https://github.com/luigisaetta/whisper-app/blob/main/match_layers.ipynb">https://github.com/luigisaetta/whisper-app/blob/main/match_layers.ipynb</a><br><a target="_blank" rel="noopener" href="https://www.mlq.ai/openai-whisper-gpt-3-fine-tuning-youtube-video/">https://www.mlq.ai/openai-whisper-gpt-3-fine-tuning-youtube-video/</a><br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/71561761/how-to-load-a-fine-tuned-pytorch-huggingface-bert-model-from-a-checkpoint-file">https://stackoverflow.com/questions/71561761/how-to-load-a-fine-tuned-pytorch-huggingface-bert-model-from-a-checkpoint-file</a><br><a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1P4ClLkPmfsaKn2tBbRp0nVjGMRKR-EWz">https://colab.research.google.com/drive/1P4ClLkPmfsaKn2tBbRp0nVjGMRKR-EWz</a><br><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/openai/whisper/discussions/6">https://huggingface.co/spaces/openai/whisper/discussions/6</a><br><a target="_blank" rel="noopener" href="https://huggingface.co/blog/fine-tune-whisper">https://huggingface.co/blog/fine-tune-whisper</a><br><a target="_blank" rel="noopener" href="https://github.com/openai/whisper/discussions/98">https://github.com/openai/whisper/discussions/98</a></p>

    </div>
</article>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%A3%E7%B5%90"><span class="toc-number">1.</span> <span class="toc-text">連結</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E9%BB%9E%E5%B0%88%E6%A1%88%E7%B5%90%E6%A7%8B"><span class="toc-number">2.</span> <span class="toc-text">重點專案結構</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%89%E8%A3%9D-cuda"><span class="toc-number">3.</span> <span class="toc-text">安裝 cuda</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cuda"><span class="toc-number">3.0.0.1.</span> <span class="toc-text">cuda</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#driver"><span class="toc-number">3.0.0.2.</span> <span class="toc-text">driver</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Huggingface-%E9%87%91%E9%91%B0%E7%94%B3%E8%AB%8B"><span class="toc-number">4.</span> <span class="toc-text">Huggingface 金鑰申請</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A8%8B%E5%BC%8F%E7%A2%BC%E8%AA%AA%E6%98%8E"><span class="toc-number">5.</span> <span class="toc-text">程式碼說明</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%E5%90%8D%E7%A8%B1"><span class="toc-number">5.0.0.1.</span> <span class="toc-text">建立模型名稱</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%99%BB%E5%85%A5-hugging-face"><span class="toc-number">5.0.0.2.</span> <span class="toc-text">登入 hugging face</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BC%89%E5%85%A5%E9%9F%B3%E6%AA%94%E8%B3%87%E6%96%99"><span class="toc-number">5.0.0.3.</span> <span class="toc-text">載入音檔資料</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BC%89%E5%85%A5-Openai-%E5%BB%BA%E7%AB%8B%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.0.0.4.</span> <span class="toc-text">載入 Openai 建立好的模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AA%9E%E6%96%99%E8%BD%89%E6%8F%9B%E5%8F%96%E6%A8%A3%E7%8E%87"><span class="toc-number">5.0.0.5.</span> <span class="toc-text">語料轉換取樣率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#data-collator"><span class="toc-number">5.0.0.6.</span> <span class="toc-text">data_collator</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#compute-metrics"><span class="toc-number">5.0.0.7.</span> <span class="toc-text">compute_metrics</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#model"><span class="toc-number">5.0.0.8.</span> <span class="toc-text">model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#training-args"><span class="toc-number">5.0.0.9.</span> <span class="toc-text">training_args</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#trainer"><span class="toc-number">5.0.0.10.</span> <span class="toc-text">trainer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%96%8B%E5%A7%8B%E8%A8%93%E7%B7%B4"><span class="toc-number">5.0.0.11.</span> <span class="toc-text">開始訓練</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%9E%E6%9C%AC%E5%9C%B0%E4%B8%8A%E5%82%B3%E6%A8%A1%E5%9E%8B%E5%88%B0-HuggingFace"><span class="toc-number">5.0.0.12.</span> <span class="toc-text">從本地上傳模型到 HuggingFace</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%9E-HuggingFace-%E4%B8%8B%E8%BC%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.0.0.13.</span> <span class="toc-text">從 HuggingFace 下載模型</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#reference"><span class="toc-number">6.</span> <span class="toc-text">reference</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&text=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&is_video=false&description=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Openai Whisper Fine-Tuning - Hakka&body=Check out this article: http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&title=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&name=Openai Whisper Fine-Tuning - Hakka&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2023/07/04/Openai-Whisper-Fine-Tuning-Hakka/&t=Openai Whisper Fine-Tuning - Hakka"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2025
    Aura
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
